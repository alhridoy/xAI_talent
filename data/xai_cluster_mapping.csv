xai_cluster,researcher_name,company,title,match_score,expertise_1,expertise_2
1. Core Model Training & Scaling,Sylvie Shi,Cohere,LLM Pre-training at Cohere,3,Large Language Model Pre-training and Architecture,Semantic Search and Document Reranking with LLMs
2. Post-Training & Alignment,Shun Zhang,NVIDIA,Embodied AI + Reasoning @ NVIDIA,4,"Reinforcement Learning (policy optimization, safe/adaptive RL)",Large Language Models (LLM-based planning and code generation)
3. Reasoning & Efficiency,Fuzhao Xue,Google DeepMind,Large Language Model Researcher | HomePage (xuefuzhao.github.io),3,"Large-scale LLM architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini))","Transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023))"
3. Reasoning & Efficiency,Shangda Li,NVIDIA,"Large Language Model, Machine Learning, Ads Automated Bidding, Recommender Syste",3,Large Language Model development and tuning,Machine Learning for Ads optimization and Recommender Systems
4. Multimodal & Generation,Fuzhao Xue,Google DeepMind,Large Language Model Researcher | HomePage (xuefuzhao.github.io),4,"Large-scale LLM architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini))","Transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023))"
4. Multimodal & Generation,Sagar Vaze,Mistral AI,Multimodal LLMs @ Mistral AI,4,Multimodal vision-language and audio-language modeling,Large language model architecture design and fine-tuning
4. Multimodal & Generation,Khyathi Chandu,Mistral AI,"Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU",4,"**Multimodal Language Models:** Designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio–language “Voxtral” models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)).",**LLM Reasoning & Chain-of-Thought:** Developing reasoning architectures and chain-of-thought techniques for LLMs (e.g. “Magistral” models for long-form reasoning).
5. Coding Agents & RL,Shun Zhang,NVIDIA,Embodied AI + Reasoning @ NVIDIA,6,"Reinforcement Learning (policy optimization, safe/adaptive RL)",Large Language Models (LLM-based planning and code generation)
5. Coding Agents & RL,Jonathan Raiman,NVIDIA,"AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, De",5,"Reinforcement Learning & Multi-Agent Systems (game AI, hardware optimization)",Large-Scale Transformer Language Models & Embeddings (LLM training and representation)
5. Coding Agents & RL,Shangda Li,NVIDIA,"Large Language Model, Machine Learning, Ads Automated Bidding, Recommender Syste",5,Large Language Model development and tuning,Machine Learning for Ads optimization and Recommender Systems
5. Coding Agents & RL,Deepa Nalla,xAI,AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Pyth,3,Large Language Models (LLMs) and Generative AI systems,Autonomous “agentic” AI and multi-step AI agents
5. Coding Agents & RL,Sagar Vaze,Mistral AI,Multimodal LLMs @ Mistral AI,3,Multimodal vision-language and audio-language modeling,Large language model architecture design and fine-tuning
5. Coding Agents & RL,Abhinav Rastogi,Mistral AI,Research Scientist at Mistral AI | LLM Reasoning,3,**LLM Fine-tuning & Adaptation** (PEFT/LoRA techniques for multi-task LLMs),**Reinforcement Learning for LLM Reasoning** (RLHF pipelines to instill chain-of-thought)
8. Evaluation & Benchmarking,Khyathi Chandu,Mistral AI,"Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU",5,"**Multimodal Language Models:** Designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio–language “Voxtral” models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)).",**LLM Reasoning & Chain-of-Thought:** Developing reasoning architectures and chain-of-thought techniques for LLMs (e.g. “Magistral” models for long-form reasoning).
8. Evaluation & Benchmarking,Sylvie Shi,Cohere,LLM Pre-training at Cohere,4,Large Language Model Pre-training and Architecture,Semantic Search and Document Reranking with LLMs
8. Evaluation & Benchmarking,Jonathan Raiman,NVIDIA,"AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, De",3,"Reinforcement Learning & Multi-Agent Systems (game AI, hardware optimization)",Large-Scale Transformer Language Models & Embeddings (LLM training and representation)
8. Evaluation & Benchmarking,Abhinav Rastogi,Mistral AI,Research Scientist at Mistral AI | LLM Reasoning,3,**LLM Fine-tuning & Adaptation** (PEFT/LoRA techniques for multi-task LLMs),**Reinforcement Learning for LLM Reasoning** (RLHF pipelines to instill chain-of-thought)
8. Evaluation & Benchmarking,Deepa Nalla,xAI,AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Pyth,2,Large Language Models (LLMs) and Generative AI systems,Autonomous “agentic” AI and multi-step AI agents
