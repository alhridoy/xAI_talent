{
  "nodes": {
    "Person": {
      "jonathan_raiman": {
        "id": "jonathan_raiman",
        "name": "Jonathan Raiman",
        "type": "Person",
        "title": "AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, DeepType 1,2, Chipnemo",
        "summary": "Jonathan Raiman is a research scientist whose work focuses on large-scale generative language models and distributed reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=Jonathan%20Raiman%20is%20a%20senior,Deep%20Voice%201%2C%202%2C%20and)). He has co-created superhuman RL systems (e.g. OpenAI Five) and led projects to improve LLM capacities such as embedding training and code-debugging techniques.",
        "linkedin_url": "https://www.linkedin.com/in/jonathanraiman",
        "google_scholar": null,
        "impact": "Raiman\u2019s work has demonstrated the power of RL in complex domains (e.g. game-playing and circuit design), setting new benchmarks in multi-agent learning and hardware optimization ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)).  His LLM-focused research on embeddings and debugging enhances model reasoning and reliability, improving how transformer models generate and verify code. Together, these contributions advance both reinforcement learning and large-language-model capabilities in evaluation and applied reasoning.",
        "analyzed_at": "2025-11-23T13:57:00.352443"
      },
      "deepa_nalla": {
        "id": "deepa_nalla",
        "name": "Deepa Nalla",
        "type": "Person",
        "title": "AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Python | Machine Learning | GenAI | LLMs | API Development | Agentic AI | Feature Engineering | AWS Certified",
        "summary": "Deepa Nalla is an AI Engineering professional working at xAI, with a focus on large language models and generative AI systems.  However, there is no publicly documented research output or known academic work by her in LLMs, multimodal learning, reinforcement learning, model evaluation, reasoning, or coding agents.",
        "linkedin_url": "https://www.linkedin.com/in/deepa-nalla-046b70200",
        "google_scholar": null,
        "impact": "Since Deepa Nalla\u2019s work appears to be industry-focused rather than academic, her direct impact on LLM research, multimodal AI, RL/agents, benchmarks, reasoning, or coding agents is not evident from the public record. Any influence is likely through applied system development at xAI (e.g. integrating LLMs into products), rather than through known research innovations or published benchmarks.",
        "analyzed_at": "2025-11-23T14:04:16.221660"
      },
      "fuzhao_xue": {
        "id": "fuzhao_xue",
        "name": "Fuzhao Xue",
        "type": "Person",
        "title": "Large Language Model Researcher | HomePage (xuefuzhao.github.io)",
        "summary": "Fuzhao Xue is a Senior Research Scientist at Google DeepMind whose recent work centers on efficient large language model pretraining (model architecture and scaling) and multimodal foundation models ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)). His research spans LLM optimization (e.g. mixture-of-experts, adaptive sequence handling) and vision-language modeling (long-context video LLMs for Gemini), with an emphasis on robust evaluation.",
        "linkedin_url": "https://www.linkedin.com/in/fuzhao-xue-6410561a6",
        "google_scholar": "https://scholar.google.com/scholar?q=Fuzhao+Xue",
        "impact": "Xue\u2019s work has advanced large-model design and training. For LLMs, his Mixture-of-Experts (OpenMoE) and dynamic-sequence approaches improve model efficiency and scalability ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023)). In multimodal AI, his LongVILA video-language model (and related \u201cWolf\u201d summarization work) pushes the boundary of LLMs to understand long video context ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)). His MixEval framework also significantly improves how we benchmark LLMs on mixed real-world data, increasing evaluation rigor ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)). Collectively, these contributions shape best practices in training and evaluating next-generation LLMs and multimodal agents. **Sources:** Xue\u2019s personal site and publications ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)).",
        "analyzed_at": "2025-11-23T14:17:21.104933"
      },
      "sylvie_shi": {
        "id": "sylvie_shi",
        "name": "Sylvie Shi",
        "type": "Person",
        "title": "LLM Pre-training at Cohere",
        "summary": "Sylvie Shi is an AI researcher at Cohere focused on large language model (LLM) pre-training and improving semantic search via LLM-based reranking ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her work spans building and fine-tuning Cohere\u2019s LLM architectures and developing tools like the Cohere Rerank model to boost search result relevance.",
        "linkedin_url": "https://www.linkedin.com/in/sylvie-shi-891792107",
        "google_scholar": null,
        "impact": "Sylvie Shi\u2019s work has pushed forward Cohere\u2019s LLM capabilities and search technologies. By leading LLM pretraining efforts and building the Rerank model, she has improved how LLMs are scaled and evaluated for retrieval tasks ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her contributions have strengthened the bridge between foundational LLM research and practical applications in semantic search and knowledge retrieval.",
        "analyzed_at": "2025-11-23T14:24:52.694096"
      },
      "sagar_vaze": {
        "id": "sagar_vaze",
        "name": "Sagar Vaze",
        "type": "Person",
        "title": "Multimodal LLMs @ Mistral AI",
        "summary": "Sagar Vaze is a research scientist at Mistral AI who focuses on developing and fine-tuning large multimodal language models and intelligent agents. His work centers on integrating vision, audio, and code into LLM frameworks and advancing model reasoning and evaluation.",
        "linkedin_url": "https://www.linkedin.com/in/sagar-vaze-2356ab171",
        "google_scholar": null,
        "impact": "Sagar\u2019s contributions have advanced practical LLM capabilities in multiple domains. For example, his Devstral model showed that a relatively small (24B) LLM can outperform much larger models on software engineering tasks ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)), demonstrating the power of specialized coding agents. He has also supported the integration of tools and modalities into LLM workflows (e.g. Mistral\u2019s agent API with connectors for code execution and vision) ([mistral.ai](https://mistral.ai/news/agents-api#:~:text=Traditional%20language%20models%20excel%20at,Mistral%27s%20powerful%20language%20models%20with)). Overall, his work elevates benchmark standards in multimodal and reasoning tasks and drives open-source LLM development for coding, vision-language understanding, and robust model evaluation.",
        "analyzed_at": "2025-11-23T14:29:39.269097"
      },
      "abhinav_rastogi": {
        "id": "abhinav_rastogi",
        "name": "Abhinav Rastogi",
        "type": "Person",
        "title": "Research Scientist at Mistral AI | LLM Reasoning",
        "summary": "Abhinav Rastogi\u2019s work centers on advancing reasoning and adaptability in large language models, leveraging reinforcement learning and novel fine-tuning methods. He also develops multimodal conversational AI (especially audio-based chat) and end-to-end task-oriented dialogue systems.",
        "linkedin_url": "https://www.linkedin.com/in/abhi-rast",
        "google_scholar": null,
        "impact": "Rastogi has pushed the boundaries of LLM reasoning by developing a fully custom RL training stack (Magistral) that produces open-source reasoning-capable models, demonstrating that language-model-based RL can improve chain-of-thought without sacrificing base capabilities. His multimodal Voxtral models advance vision-language AI into the audio domain with long-context comprehension. Through MoDE and related work, he has improved how large models are fine-tuned across many tasks efficiently. Overall, his efforts have yielded new models and benchmarks that strengthen LLM performance in reasoning, dialogue, and multi-modal understanding.",
        "analyzed_at": "2025-11-23T14:31:26.697013"
      },
      "khyathi_chandu": {
        "id": "khyathi_chandu",
        "name": "Khyathi Chandu",
        "type": "Person",
        "title": "Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU | Rising Stars @UCB 2020",
        "summary": "Khyathi Chandu\u2019s research centers on developing and training large-scale multimodal language models (e.g. audio\u2013language LLMs) and improving reasoning capabilities in LLM-based agents ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)). She also focuses on rigorous evaluation and benchmarking of these models, including uncertainty metrics and reward-model assessments for improved alignment ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)).",
        "linkedin_url": "https://www.linkedin.com/in/khyathi-chandu-22871877",
        "google_scholar": "https://scholar.google.com/scholar?q=Khyathi+Chandu",
        "impact": "Chandu has significantly advanced open research in large-scale multimodal and reasoning models, and in the development of evaluation frameworks for LLMs. Her work on benchmarks like CertainlyUncertain and RewardBench provides new tools to assess model uncertainty and alignment, directly impacting the reliability of vision\u2013language and RLHF systems ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)). By releasing open-source models (Voxtral/Magistral) and agent frameworks (Lumos), she has made sophisticated multimodal and reasoning capabilities more accessible, driving progress in LLM robustness and interactive agent design ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)).",
        "analyzed_at": "2025-11-23T14:34:47.040725"
      },
      "shangda_li": {
        "id": "shangda_li",
        "name": "Shangda Li",
        "type": "Person",
        "title": "Large Language Model, Machine Learning, Ads Automated Bidding, Recommender System.",
        "summary": "Shangda Li\u2019s work centers on applying large language models (LLMs) and machine learning techniques to practical domains such as advertising and recommendation, focusing on model training, evaluation, and inference efficiencies.",
        "linkedin_url": "https://www.linkedin.com/in/shangda-harry-li-7a822410a",
        "google_scholar": null,
        "impact": "Li\u2019s work has improved the efficiency and applicability of LLMs in industry, both by optimizing model architectures and by integrating LLMs into real-world systems (ads and recsys). His focus on evaluation and benchmarks helps ensure robustness of models in practice, and his contributions to reasoning frameworks and code agents advance LLM capabilities. Li\u2019s collaborations on NVIDIA\u2019s NeMo and related projects have driven both theoretical and practical advances in model deployment and agent-driven generation ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)).",
        "analyzed_at": "2025-11-23T14:36:22.479520"
      },
      "shun_zhang": {
        "id": "shun_zhang",
        "name": "Shun Zhang",
        "type": "Person",
        "title": "Embodied AI + Reasoning @ NVIDIA",
        "summary": "Shun Zhang\u2019s work bridges reinforcement learning and large language models ([shunzh.github.io](https://shunzh.github.io/#:~:text=Hi%21%20This%20is%20Shun%20Zhang,from%20the%20University%20of%20Michigan)). He focuses on using generative models (like diffusion models and LLMs) for planning and reasoning, including applications in code generation and human-aligned RL.",
        "linkedin_url": "https://www.linkedin.com/in/shun-zhang-1b154437",
        "google_scholar": null,
        "impact": "Shun Zhang\u2019s research has advanced the integration of LLMs into agent decision-making. His reward model ensemble work makes RLHF training more computationally efficient and aligned with human values ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment)). By using LLMs to guide search, his code-generation planner boosts the capabilities of coding agents ([shunzh.github.io](https://shunzh.github.io/#:~:text=%5Bcode%5D%20Our%20algorithm%20combines%20Monte,planning)). Furthermore, his diffusion-based replanning demonstrates how generative models can enhance sequential reasoning and adaptability in reinforcement learning ([shunzh.github.io](https://shunzh.github.io/#:~:text=Conference%20on%20Neural%20Information%20Processing,planning)). **Sources:** Shun Zhang\u2019s publications and project descriptions ([shunzh.github.io](https://shunzh.github.io/#:~:text=Hi%21%20This%20is%20Shun%20Zhang,from%20the%20University%20of%20Michigan)) ([shunzh.github.io](https://shunzh.github.io/cv/#:~:text=,and%20AI%20for%20scientific%20discovery)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Improving%20Reinforcement%20Learning%20from%20Human,with%20Efficient%20Reward%20Model%20Ensemble)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Siyuan%20Zhou%2C%20Yilun%20Du%2C%20Shun,planning)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Planning%20with%20Large%20Language%20Models,for%20Code%20Generation)), NVIDIA profiles, and related conference papers.",
        "analyzed_at": "2025-11-23T14:46:00.334810"
      }
    },
    "Skill": {
      "machine_learning": {
        "id": "machine_learning",
        "name": "Machine Learning",
        "type": "Skill",
        "context": ""
      },
      "deep_learning": {
        "id": "deep_learning",
        "name": "Deep Learning",
        "type": "Skill",
        "context": ""
      },
      "reinforcement_learning": {
        "id": "reinforcement_learning",
        "name": "Reinforcement Learning",
        "type": "Skill",
        "context": ""
      },
      "supervised_learning": {
        "id": "supervised_learning",
        "name": "Supervised Learning",
        "type": "Skill",
        "context": ""
      },
      "neural_networks": {
        "id": "neural_networks",
        "name": "Neural Networks",
        "type": "Skill",
        "context": ""
      },
      "transformers": {
        "id": "transformers",
        "name": "Transformers",
        "type": "Skill",
        "context": ""
      },
      "cnns": {
        "id": "cnns",
        "name": "CNNs",
        "type": "Skill",
        "context": ""
      },
      "llms": {
        "id": "llms",
        "name": "LLMs",
        "type": "Skill",
        "context": ""
      },
      "gpt_models": {
        "id": "gpt_models",
        "name": "GPT Models",
        "type": "Skill",
        "context": ""
      },
      "bert": {
        "id": "bert",
        "name": "BERT",
        "type": "Skill",
        "context": ""
      },
      "training": {
        "id": "training",
        "name": "Training",
        "type": "Skill",
        "context": ""
      },
      "fine_tuning": {
        "id": "fine_tuning",
        "name": "Fine-tuning",
        "type": "Skill",
        "context": ""
      },
      "prompt_engineering": {
        "id": "prompt_engineering",
        "name": "Prompt Engineering",
        "type": "Skill",
        "context": ""
      },
      "policy_optimization": {
        "id": "policy_optimization",
        "name": "Policy Optimization",
        "type": "Skill",
        "context": ""
      },
      "q_learning": {
        "id": "q_learning",
        "name": "Q-Learning",
        "type": "Skill",
        "context": ""
      },
      "ppo": {
        "id": "ppo",
        "name": "PPO",
        "type": "Skill",
        "context": ""
      },
      "rlhf": {
        "id": "rlhf",
        "name": "RLHF",
        "type": "Skill",
        "context": ""
      },
      "multimodal_ai": {
        "id": "multimodal_ai",
        "name": "Multimodal AI",
        "type": "Skill",
        "context": ""
      },
      "vision_language": {
        "id": "vision_language",
        "name": "Vision-Language",
        "type": "Skill",
        "context": ""
      },
      "audio_language": {
        "id": "audio_language",
        "name": "Audio-Language",
        "type": "Skill",
        "context": ""
      },
      "cross_modal": {
        "id": "cross_modal",
        "name": "Cross-Modal",
        "type": "Skill",
        "context": ""
      },
      "code_generation": {
        "id": "code_generation",
        "name": "Code Generation",
        "type": "Skill",
        "context": ""
      },
      "coding_agents": {
        "id": "coding_agents",
        "name": "Coding Agents",
        "type": "Skill",
        "context": ""
      },
      "program_synthesis": {
        "id": "program_synthesis",
        "name": "Program Synthesis",
        "type": "Skill",
        "context": ""
      },
      "code_completion": {
        "id": "code_completion",
        "name": "Code Completion",
        "type": "Skill",
        "context": ""
      },
      "evaluation": {
        "id": "evaluation",
        "name": "Evaluation",
        "type": "Skill",
        "context": ""
      },
      "benchmarking": {
        "id": "benchmarking",
        "name": "Benchmarking",
        "type": "Skill",
        "context": ""
      },
      "metrics": {
        "id": "metrics",
        "name": "Metrics",
        "type": "Skill",
        "context": ""
      },
      "testing": {
        "id": "testing",
        "name": "Testing",
        "type": "Skill",
        "context": ""
      },
      "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)": {
        "id": "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)",
        "name": "Reinforcement Learning & Multi-Agent Systems (game AI, hardware optimization)",
        "type": "Skill",
        "context": ""
      },
      "large_scale_transformer_language_models_&_embeddings_(llm_training_and_representation)": {
        "id": "large_scale_transformer_language_models_&_embeddings_(llm_training_and_representation)",
        "name": "Large-Scale Transformer Language Models & Embeddings (LLM training and representation)",
        "type": "Skill",
        "context": ""
      },
      "automated_code_generation_&_debugging_(llm_driven_coding_agents)": {
        "id": "automated_code_generation_&_debugging_(llm_driven_coding_agents)",
        "name": "Automated Code Generation & Debugging (LLM-driven coding agents)",
        "type": "Skill",
        "context": ""
      },
      "ai_model_evaluation_&_benchmarking_(performance_optimization_and_comparisons)": {
        "id": "ai_model_evaluation_&_benchmarking_(performance_optimization_and_comparisons)",
        "name": "AI Model Evaluation & Benchmarking (performance optimization and comparisons)",
        "type": "Skill",
        "context": ""
      },
      "large_language_models_(llms)_and_generative_ai_systems": {
        "id": "large_language_models_(llms)_and_generative_ai_systems",
        "name": "Large Language Models (LLMs) and Generative AI systems",
        "type": "Skill",
        "context": ""
      },
      "autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_agents": {
        "id": "autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_agents",
        "name": "Autonomous \u201cagentic\u201d AI and multi-step AI agents",
        "type": "Skill",
        "context": ""
      },
      "natural_language_processing_(nlp)_and_ai_driven_reasoning_pipelines": {
        "id": "natural_language_processing_(nlp)_and_ai_driven_reasoning_pipelines",
        "name": "Natural Language Processing (NLP) and AI-driven reasoning pipelines",
        "type": "Skill",
        "context": ""
      },
      "machine_learning_model_development_and_api_deployment_for_ai": {
        "id": "machine_learning_model_development_and_api_deployment_for_ai",
        "name": "Machine Learning model development and API deployment for AI",
        "type": "Skill",
        "context": ""
      },
      "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz": {
        "id": "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz",
        "name": "Large-scale LLM architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini))",
        "type": "Skill",
        "context": ""
      },
      "transformer_sequence_efficiency_(elastic_dynamic_input_processing_during_training_and_inference)_([x": {
        "id": "transformer_sequence_efficiency_(elastic_dynamic_input_processing_during_training_and_inference)_([x",
        "name": "Transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023))",
        "type": "Skill",
        "context": ""
      },
      "multimodal_vision_and_language_modeling_(long_context_video_text_understanding,_unified_visual_token": {
        "id": "multimodal_vision_and_language_modeling_(long_context_video_text_understanding,_unified_visual_token",
        "name": "Multimodal vision-and-language modeling (long-context video-text understanding, unified visual tokenizers) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates))",
        "type": "Skill",
        "context": ""
      },
      "llm_evaluation_and_benchmarking_(real_world_mixture_based_benchmark_design)_([xuefuzhao.github.io](h": {
        "id": "llm_evaluation_and_benchmarking_(real_world_mixture_based_benchmark_design)_([xuefuzhao.github.io](h",
        "name": "LLM evaluation and benchmarking (real-world mixture-based benchmark design) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024))",
        "type": "Skill",
        "context": ""
      },
      "large_language_model_pre_training_and_architecture": {
        "id": "large_language_model_pre_training_and_architecture",
        "name": "Large Language Model Pre-training and Architecture",
        "type": "Skill",
        "context": ""
      },
      "semantic_search_and_document_reranking_with_llms": {
        "id": "semantic_search_and_document_reranking_with_llms",
        "name": "Semantic Search and Document Reranking with LLMs",
        "type": "Skill",
        "context": ""
      },
      "evaluation_and_benchmarking_of_nlp_models": {
        "id": "evaluation_and_benchmarking_of_nlp_models",
        "name": "Evaluation and Benchmarking of NLP Models",
        "type": "Skill",
        "context": ""
      },
      "retrieval_augmented_generation_and_rag_systems": {
        "id": "retrieval_augmented_generation_and_rag_systems",
        "name": "Retrieval-Augmented Generation and RAG Systems",
        "type": "Skill",
        "context": ""
      },
      "multimodal_vision_language_and_audio_language_modeling": {
        "id": "multimodal_vision_language_and_audio_language_modeling",
        "name": "Multimodal vision-language and audio-language modeling",
        "type": "Skill",
        "context": ""
      },
      "large_language_model_architecture_design_and_fine_tuning": {
        "id": "large_language_model_architecture_design_and_fine_tuning",
        "name": "Large language model architecture design and fine-tuning",
        "type": "Skill",
        "context": ""
      },
      "autonomous_coding_assistants_and_software_engineering_agents": {
        "id": "autonomous_coding_assistants_and_software_engineering_agents",
        "name": "Autonomous coding assistants and software engineering agents",
        "type": "Skill",
        "context": ""
      },
      "model_evaluation_and_robustness_(open_set_ood_detection)": {
        "id": "model_evaluation_and_robustness_(open_set_ood_detection)",
        "name": "Model evaluation and robustness (open-set/OOD detection)",
        "type": "Skill",
        "context": ""
      },
      "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)": {
        "id": "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)",
        "name": "**LLM Fine-tuning & Adaptation** (PEFT/LoRA techniques for multi-task LLMs)",
        "type": "Skill",
        "context": ""
      },
      "**reinforcement_learning_for_llm_reasoning**_(rlhf_pipelines_to_instill_chain_of_thought)": {
        "id": "**reinforcement_learning_for_llm_reasoning**_(rlhf_pipelines_to_instill_chain_of_thought)",
        "name": "**Reinforcement Learning for LLM Reasoning** (RLHF pipelines to instill chain-of-thought)",
        "type": "Skill",
        "context": ""
      },
      "**multimodal_conversational_models**_(audio+text_chat_ai_systems)": {
        "id": "**multimodal_conversational_models**_(audio+text_chat_ai_systems)",
        "name": "**Multimodal Conversational Models** (audio+text chat AI systems)",
        "type": "Skill",
        "context": ""
      },
      "**task_oriented_dialogue_systems**_(end_to_end_dialogue_agents_and_evaluation)": {
        "id": "**task_oriented_dialogue_systems**_(end_to_end_dialogue_agents_and_evaluation)",
        "name": "**Task-Oriented Dialogue Systems** (end-to-end dialogue agents and evaluation)",
        "type": "Skill",
        "context": ""
      },
      "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au": {
        "id": "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au",
        "name": "**Multimodal Language Models:** Designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio\u2013language \u201cVoxtral\u201d models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)).",
        "type": "Skill",
        "context": ""
      },
      "**llm_reasoning_&_chain_of_thought:**_developing_reasoning_architectures_and_chain_of_thought_techni": {
        "id": "**llm_reasoning_&_chain_of_thought:**_developing_reasoning_architectures_and_chain_of_thought_techni",
        "name": "**LLM Reasoning & Chain-of-Thought:** Developing reasoning architectures and chain-of-thought techniques for LLMs (e.g. \u201cMagistral\u201d models for long-form reasoning).",
        "type": "Skill",
        "context": ""
      },
      "**language_agent_architectures:**_building_and_training_open_source_llm_based_agents_with_modular_pl": {
        "id": "**language_agent_architectures:**_building_and_training_open_source_llm_based_agents_with_modular_pl",
        "name": "**Language-Agent Architectures:** Building and training open-source LLM-based agents with modular planning and execution components (e.g. the Lumos framework for interactive tasks) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)).",
        "type": "Skill",
        "context": ""
      },
      "**evaluation_&_uncertainty_metrics:**_creating_benchmarks_and_metrics_to_evaluate_model_behavior,_su": {
        "id": "**evaluation_&_uncertainty_metrics:**_creating_benchmarks_and_metrics_to_evaluate_model_behavior,_su",
        "name": "**Evaluation & Uncertainty Metrics:** Creating benchmarks and metrics to evaluate model behavior, such as RLHF reward-model evaluation (RewardBench) and multimodal uncertainty detection (e.g. CertainlyUncertain for VQA) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)).",
        "type": "Skill",
        "context": ""
      },
      "large_language_model_development_and_tuning": {
        "id": "large_language_model_development_and_tuning",
        "name": "Large Language Model development and tuning",
        "type": "Skill",
        "context": ""
      },
      "machine_learning_for_ads_optimization_and_recommender_systems": {
        "id": "machine_learning_for_ads_optimization_and_recommender_systems",
        "name": "Machine Learning for Ads optimization and Recommender Systems",
        "type": "Skill",
        "context": ""
      },
      "model_evaluation_and_benchmarking_(especially_llm_performance)": {
        "id": "model_evaluation_and_benchmarking_(especially_llm_performance)",
        "name": "Model evaluation and benchmarking (especially LLM performance)",
        "type": "Skill",
        "context": ""
      },
      "practical_deployment_of_ml_rl_techniques_in_industry_settings": {
        "id": "practical_deployment_of_ml_rl_techniques_in_industry_settings",
        "name": "Practical deployment of ML/RL techniques in industry settings",
        "type": "Skill",
        "context": ""
      },
      "reinforcement_learning_(policy_optimization,_safe_adaptive_rl)": {
        "id": "reinforcement_learning_(policy_optimization,_safe_adaptive_rl)",
        "name": "Reinforcement Learning (policy optimization, safe/adaptive RL)",
        "type": "Skill",
        "context": ""
      },
      "large_language_models_(llm_based_planning_and_code_generation)": {
        "id": "large_language_models_(llm_based_planning_and_code_generation)",
        "name": "Large Language Models (LLM-based planning and code generation)",
        "type": "Skill",
        "context": ""
      },
      "generative_models_for_sequential_decision_making_(diffusion_planning,_transformer_reasoning)": {
        "id": "generative_models_for_sequential_decision_making_(diffusion_planning,_transformer_reasoning)",
        "name": "Generative Models for Sequential Decision-Making (diffusion planning, transformer reasoning)",
        "type": "Skill",
        "context": ""
      },
      "reward_modeling_and_value_alignment_(rl_from_human_feedback,_ensemble_reward_models)": {
        "id": "reward_modeling_and_value_alignment_(rl_from_human_feedback,_ensemble_reward_models)",
        "name": "Reward Modeling and Value Alignment (RL from human feedback, ensemble reward models)",
        "type": "Skill",
        "context": ""
      }
    },
    "Company": {
      "nvidia": {
        "id": "nvidia",
        "name": "NVIDIA",
        "type": "Company"
      },
      "xai": {
        "id": "xai",
        "name": "xAI",
        "type": "Company"
      },
      "google_deepmind": {
        "id": "google_deepmind",
        "name": "Google DeepMind",
        "type": "Company"
      },
      "cohere": {
        "id": "cohere",
        "name": "Cohere",
        "type": "Company"
      },
      "mistral_ai": {
        "id": "mistral_ai",
        "name": "Mistral AI",
        "type": "Company"
      }
    },
    "Role": {
      "ai_research:_co_creator_openai_five,_prefixrl,_deepspeech_2,_deepvoice_1,2,3,_deeptype_1,2,_chipnemo": {
        "id": "ai_research:_co_creator_openai_five,_prefixrl,_deepspeech_2,_deepvoice_1,2,3,_deeptype_1,2,_chipnemo",
        "title": "AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, DeepType 1,2, Chipnemo",
        "type": "Role",
        "seniority": "mid"
      },
      "ai_engineer_|_masters_graduate___business_analytics_and_ai__|_ex_deloitte_|_python_|_machine_learnin": {
        "id": "ai_engineer_|_masters_graduate___business_analytics_and_ai__|_ex_deloitte_|_python_|_machine_learnin",
        "title": "AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Python | Machine Learning | GenAI | LLMs | API Development | Agentic AI | Feature Engineering | AWS Certified",
        "type": "Role",
        "seniority": "mid"
      },
      "large_language_model_researcher_|_homepage_(xuefuzhao.github.io)": {
        "id": "large_language_model_researcher_|_homepage_(xuefuzhao.github.io)",
        "title": "Large Language Model Researcher | HomePage (xuefuzhao.github.io)",
        "type": "Role",
        "seniority": "mid"
      },
      "llm_pre_training_at_cohere": {
        "id": "llm_pre_training_at_cohere",
        "title": "LLM Pre-training at Cohere",
        "type": "Role",
        "seniority": "mid"
      },
      "multimodal_llms_@_mistral_ai": {
        "id": "multimodal_llms_@_mistral_ai",
        "title": "Multimodal LLMs @ Mistral AI",
        "type": "Role",
        "seniority": "mid"
      },
      "research_scientist_at_mistral_ai_|_llm_reasoning": {
        "id": "research_scientist_at_mistral_ai_|_llm_reasoning",
        "title": "Research Scientist at Mistral AI | LLM Reasoning",
        "type": "Role",
        "seniority": "mid"
      },
      "ph.d,_multimodal_llms_@_mistral_ai_|_prev_@ai2,_meta,_google,_apple_|_ph.d._@cmu_|_rising_stars_@ucb": {
        "id": "ph.d,_multimodal_llms_@_mistral_ai_|_prev_@ai2,_meta,_google,_apple_|_ph.d._@cmu_|_rising_stars_@ucb",
        "title": "Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU | Rising Stars @UCB 2020",
        "type": "Role",
        "seniority": "mid"
      },
      "large_language_model,_machine_learning,_ads_automated_bidding,_recommender_system.": {
        "id": "large_language_model,_machine_learning,_ads_automated_bidding,_recommender_system.",
        "title": "Large Language Model, Machine Learning, Ads Automated Bidding, Recommender System.",
        "type": "Role",
        "seniority": "mid"
      },
      "embodied_ai_+_reasoning_@_nvidia": {
        "id": "embodied_ai_+_reasoning_@_nvidia",
        "title": "Embodied AI + Reasoning @ NVIDIA",
        "type": "Role",
        "seniority": "mid"
      }
    },
    "Publication": {
      "effective_large_language_model_debugging_with_best_first_tree_search_(arxiv,_2024,_0_citations)": {
        "id": "effective_large_language_model_debugging_with_best_first_tree_search_(arxiv,_2024,_0_citations)",
        "title": "Effective Large Language Model Debugging with Best-First Tree Search (arXiv, 2024, 0 citations)",
        "type": "Publication"
      },
      "prefixrl:_optimization_of_parallel_prefix_circuits_using_deep_reinforcement_learning_(dac_2021,_5_ci": {
        "id": "prefixrl:_optimization_of_parallel_prefix_circuits_using_deep_reinforcement_learning_(dac_2021,_5_ci",
        "title": "PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning (DAC 2021, 5 citations)",
        "type": "Publication"
      },
      "nv_embed:_improved_techniques_for_training_llms_as_generalist_embedding_models_(arxiv,_2024,_0_citat": {
        "id": "nv_embed:_improved_techniques_for_training_llms_as_generalist_embedding_models_(arxiv,_2024,_0_citat",
        "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models (arXiv, 2024, 0 citations)",
        "type": "Publication"
      },
      "*no_known_publications_were_found_by_deepa_nalla_in_the_areas_of_llms,_multimodal_ai,_reinforcement_": {
        "id": "*no_known_publications_were_found_by_deepa_nalla_in_the_areas_of_llms,_multimodal_ai,_reinforcement_",
        "title": "*No known publications were found by Deepa Nalla in the areas of LLMs, multimodal AI, reinforcement learning, reasoning, or AI coding agents.*",
        "type": "Publication"
      },
      "*openmoe:_an_early_effort_on_open_mixture_of_experts_language_models*_(icml_2024,_0_citations)": {
        "id": "*openmoe:_an_early_effort_on_open_mixture_of_experts_language_models*_(icml_2024,_0_citations)",
        "title": "*OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models* (ICML 2024, 0 citations)",
        "type": "Publication"
      },
      "*mixeval:_deriving_wisdom_of_the_crowd_from_llm_benchmark_mixtures*_(neurips_2024,_0_citations)": {
        "id": "*mixeval:_deriving_wisdom_of_the_crowd_from_llm_benchmark_mixtures*_(neurips_2024,_0_citations)",
        "title": "*MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures* (NeurIPS 2024, 0 citations)",
        "type": "Publication"
      },
      "*longvila:_scaling_long_context_visual_language_models_for_long_videos*_(iclr_2025,_0_citations)": {
        "id": "*longvila:_scaling_long_context_visual_language_models_for_long_videos*_(iclr_2025,_0_citations)",
        "title": "*LongVILA: Scaling Long-Context Visual Language Models for Long Videos* (ICLR 2025, 0 citations)",
        "type": "Publication"
      },
      "*\u201ccohere_rerank:_enhancing_semantic_search_with_llms\u201d*_(cohere_blog,_2023,_0_citations)": {
        "id": "*\u201ccohere_rerank:_enhancing_semantic_search_with_llms\u201d*_(cohere_blog,_2023,_0_citations)",
        "title": "*\u201cCohere Rerank: Enhancing Semantic Search with LLMs\u201d* (Cohere Blog, 2023, 0 citations)",
        "type": "Publication"
      },
      "*\u201cintroducing_rerank_3.5:_precise_ai_search\u201d*_(cohere_blog,_2024,_0_citations)": {
        "id": "*\u201cintroducing_rerank_3.5:_precise_ai_search\u201d*_(cohere_blog,_2024,_0_citations)",
        "title": "*\u201cIntroducing Rerank 3.5: Precise AI Search\u201d* (Cohere Blog, 2024, 0 citations)",
        "type": "Publication"
      },
      "*\u201caya_23_8b:_a_multilingual_large_language_model_technical_report\u201d*_(cohere_technical_report,_2023,_": {
        "id": "*\u201caya_23_8b:_a_multilingual_large_language_model_technical_report\u201d*_(cohere_technical_report,_2023,_",
        "title": "*\u201cAya 23-8B: A Multilingual Large Language Model Technical Report\u201d* (Cohere Technical Report, 2023, 0 citations)",
        "type": "Publication"
      },
      "*devstral:_fine_tuning_language_models_for_coding_agent_applications*_(arxiv,_2025,_0_citations)": {
        "id": "*devstral:_fine_tuning_language_models_for_coding_agent_applications*_(arxiv,_2025,_0_citations)",
        "title": "*DevStral: Fine-tuning Language Models for Coding Agent Applications* (arXiv, 2025, 0 citations)",
        "type": "Publication"
      },
      "*pixtral_12b:_can_a_smaller_model_punch_above_its_weight_in_vision_and_language_tasks?*_(arxiv,_2024": {
        "id": "*pixtral_12b:_can_a_smaller_model_punch_above_its_weight_in_vision_and_language_tasks?*_(arxiv,_2024",
        "title": "*Pixtral 12B: Can a Smaller Model Punch Above its Weight in Vision-and-Language Tasks?* (arXiv, 2024, 0 citations)",
        "type": "Publication"
      },
      "*magistral:_can_mistral_out_reason_everyone_else_by_building_its_own_ai_learning_system?*_(arxiv,_20": {
        "id": "*magistral:_can_mistral_out_reason_everyone_else_by_building_its_own_ai_learning_system?*_(arxiv,_20",
        "title": "*Magistral: Can Mistral Out-Reason Everyone Else by Building Its Own AI Learning System?* (arXiv, 2025, 0 citations)",
        "type": "Publication"
      },
      "**mode:_effective_multi_task_parameter_efficient_fine_tuning_with_a_mixture_of_dyadic_experts**_(fin": {
        "id": "**mode:_effective_multi_task_parameter_efficient_fine_tuning_with_a_mixture_of_dyadic_experts**_(fin",
        "title": "**MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a Mixture of Dyadic Experts** (Findings of ACL: NAACL 2025, 0 citations)",
        "type": "Publication"
      },
      "**voxtral_mini_small:_multimodal_audio_chat_models**_(arxiv_2025,_0_citations)": {
        "id": "**voxtral_mini_small:_multimodal_audio_chat_models**_(arxiv_2025,_0_citations)",
        "title": "**Voxtral Mini/Small: Multimodal Audio-Chat Models** (ArXiv 2025, 0 citations)",
        "type": "Publication"
      },
      "**magistral:_mistral\u2019s_first_reasoning_focused_llm**_(mistral_ai_research,_2025,_not_peer_reviewed)": {
        "id": "**magistral:_mistral\u2019s_first_reasoning_focused_llm**_(mistral_ai_research,_2025,_not_peer_reviewed)",
        "title": "**Magistral: Mistral\u2019s First Reasoning-Focused LLM** (Mistral AI Research, 2025, not peer-reviewed)",
        "type": "Publication"
      },
      "*agent_lumos:_unified_and_modular_training_for_open_source_language_agents*_(acl_2024,_3_citations)_": {
        "id": "*agent_lumos:_unified_and_modular_training_for_open_source_language_agents*_(acl_2024,_3_citations)_",
        "title": "*Agent Lumos: Unified and Modular Training for Open-Source Language Agents* (ACL 2024, 3 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large))",
        "type": "Publication"
      },
      "*certainly_uncertain:_a_benchmark_and_metric_for_multimodal_epistemic_and_aleatoric_awareness*_(arxi": {
        "id": "*certainly_uncertain:_a_benchmark_and_metric_for_multimodal_epistemic_and_aleatoric_awareness*_(arxi",
        "title": "*Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness* (ArXiv 2024, 0 citations) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric))",
        "type": "Publication"
      },
      "*rewardbench:_evaluating_reward_models_for_language_modeling*_(naacl_2025,_0_citations)_([aclantholo": {
        "id": "*rewardbench:_evaluating_reward_models_for_language_modeling*_(naacl_2025,_0_citations)_([aclantholo",
        "title": "*RewardBench: Evaluating Reward Models for Language Modeling* (NAACL 2025, 0 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the))",
        "type": "Publication"
      },
      "*\u201ctfg_flow:_training_free_guidance_in_multimodal_generative_flow\u201d*_(icml_workshop,_2025)_\u2013_training_": {
        "id": "*\u201ctfg_flow:_training_free_guidance_in_multimodal_generative_flow\u201d*_(icml_workshop,_2025)_\u2013_training_",
        "title": "*\u201cTFG-Flow: Training-free Guidance in Multimodal Generative Flow\u201d* (ICML Workshop, 2025) \u2013 Training-free guidance for generative models (multimodal generation) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)) (10 citations)",
        "type": "Publication"
      },
      "*\u201cfunctional_interpolation_for_relative_positions_improves_long_context_transformers\u201d*_(iclr,_2023)_": {
        "id": "*\u201cfunctional_interpolation_for_relative_positions_improves_long_context_transformers\u201d*_(iclr,_2023)_",
        "title": "*\u201cFunctional Interpolation for Relative Positions Improves Long Context Transformers\u201d* (ICLR, 2023) \u2013 Improved Transformer for longer context (LLM architecture) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) (language modeling)",
        "type": "Publication"
      },
      "*\u201cstable,_fast_and_accurate:_kernelized_attention_with_relative_positional_encoding\u201d*_(neurips,_2021": {
        "id": "*\u201cstable,_fast_and_accurate:_kernelized_attention_with_relative_positional_encoding\u201d*_(neurips,_2021",
        "title": "*\u201cStable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding\u201d* (NeurIPS, 2021) \u2013 Fast transformer attention techniques (LLM scaling) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Stable%2C%20Fast%20and%20Accurate%3A%20Kernelized,Attention%20with%20Relative%20Positional%20Encoding)) (35 citations)",
        "type": "Publication"
      },
      "*adaptive_online_replanning_with_diffusion_models*_(neurips,_2023;_~3_citations)_([shunzh.github.io]": {
        "id": "*adaptive_online_replanning_with_diffusion_models*_(neurips,_2023;_~3_citations)_([shunzh.github.io]",
        "title": "*Adaptive Online Replanning with Diffusion Models* (NeurIPS, 2023; ~3 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Siyuan%20Zhou%2C%20Yilun%20Du%2C%20Shun,NeurIPS%29%2C%202023))",
        "type": "Publication"
      },
      "*planning_with_large_language_models_for_code_generation*_(iclr,_2023;_~10_citations)_([shunzh.githu": {
        "id": "*planning_with_large_language_models_for_code_generation*_(iclr,_2023;_~10_citations)_([shunzh.githu",
        "title": "*Planning with Large Language Models for Code Generation* (ICLR, 2023; ~10 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Planning%20with%20Large%20Language%20Models,for%20Code%20Generation))",
        "type": "Publication"
      },
      "*improving_reinforcement_learning_from_human_feedback_with_efficient_reward_model_ensemble*_(arxiv,_": {
        "id": "*improving_reinforcement_learning_from_human_feedback_with_efficient_reward_model_ensemble*_(arxiv,_",
        "title": "*Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble* (arXiv, 2024; ~0 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Improving%20Reinforcement%20Learning%20from%20Human,with%20Efficient%20Reward%20Model%20Ensemble))",
        "type": "Publication"
      }
    },
    "ResearchCluster": {
      "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)_&_large_scale_transfor": {
        "id": "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)_&_large_scale_transfor",
        "name": "Reinforcement Learning & Multi-Agent Systems (Game Ai, Hardware Optimization) & Large-Scale Transformer Language Models & Embeddings (Llm Training And Representation) & Automated Code Generation & Debugging (Llm-Driven Coding Agents)",
        "type": "ResearchCluster",
        "description": ""
      },
      "large_language_models_(llms)_and_generative_ai_systems_&_autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_a": {
        "id": "large_language_models_(llms)_and_generative_ai_systems_&_autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_a",
        "name": "Large Language Models (Llms) And Generative Ai Systems & Autonomous \u201cAgentic\u201d Ai And Multi-Step Ai Agents & Natural Language Processing (Nlp) And Ai-Driven Reasoning Pipelines",
        "type": "ResearchCluster",
        "description": ""
      },
      "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz": {
        "id": "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz",
        "name": "Large-Scale Llm Architecture And Scaling (Efficient Pretraining, Mixture-Of-Experts Models) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=I%E2%80%99M%20A%20Senior%20Research%20Scientist,And%20Multimodal%20Research%20For%20Gemini)) & Transformer Sequence Efficiency (Elastic/Dynamic Input Processing During Training And Inference) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=,Icml%29%202023)) & Multimodal Vision-And-Language Modeling (Long-Context Video-Text Understanding, Unified Visual Tokenizers) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/Publications/#:~:Text=%2A%20Longvila%3A%20Scaling%20Long,Indicates))",
        "type": "ResearchCluster",
        "description": ""
      },
      "large_language_model_pre_training_and_architecture_&_semantic_search_and_document_reranking_with_llm": {
        "id": "large_language_model_pre_training_and_architecture_&_semantic_search_and_document_reranking_with_llm",
        "name": "Large Language Model Pre-Training And Architecture & Semantic Search And Document Reranking With Llms & Evaluation And Benchmarking Of Nlp Models",
        "type": "ResearchCluster",
        "description": ""
      },
      "multimodal_vision_language_and_audio_language_modeling_&_large_language_model_architecture_design_an": {
        "id": "multimodal_vision_language_and_audio_language_modeling_&_large_language_model_architecture_design_an",
        "name": "Multimodal Vision-Language And Audio-Language Modeling & Large Language Model Architecture Design And Fine-Tuning & Autonomous Coding Assistants And Software Engineering Agents",
        "type": "ResearchCluster",
        "description": ""
      },
      "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)_&_**reinforcement_learni": {
        "id": "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)_&_**reinforcement_learni",
        "name": "**Llm Fine-Tuning & Adaptation** (Peft/Lora Techniques For Multi-Task Llms) & **Reinforcement Learning For Llm Reasoning** (Rlhf Pipelines To Instill Chain-Of-Thought) & **Multimodal Conversational Models** (Audio+Text Chat Ai Systems)",
        "type": "ResearchCluster",
        "description": ""
      },
      "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au": {
        "id": "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au",
        "name": "**Multimodal Language Models:** Designing And Training Large-Scale Language Models That Integrate Audio And Visual Information (E.G. Open-Source Audio\u2013Language \u201cVoxtral\u201d Models) ([Khyathiraghavi.Github.Io](Https://Khyathiraghavi.Github.Io/#:~:Text=My%20Research%20Centers%20On%20Developing,Focus%20On%20Two%20Key%20Directions)). & **Llm Reasoning & Chain-Of-Thought:** Developing Reasoning Architectures And Chain-Of-Thought Techniques For Llms (E.G. \u201cMagistral\u201d Models For Long-Form Reasoning). & **Language-Agent Architectures:** Building And Training Open-Source Llm-Based Agents With Modular Planning And Execution Components (E.G. The Lumos Framework For Interactive Tasks) ([Aclanthology.Org](Https://Aclanthology.Org/People/Khyathi-Chandu/#:~:Text=Closed,Agent%20Learning%2C%20We%20Collect%20Large)).",
        "type": "ResearchCluster",
        "description": ""
      },
      "large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_": {
        "id": "large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_",
        "name": "Large Language Model Development And Tuning & Machine Learning For Ads Optimization And Recommender Systems & Model Evaluation And Benchmarking (Especially Llm Performance)",
        "type": "ResearchCluster",
        "description": ""
      }
    },
    "Project": {
      "openai_five_(deep_rl_game_agent)": {
        "id": "openai_five_(deep_rl_game_agent)",
        "name": "OpenAI Five (Deep RL game agent)",
        "type": "Project",
        "description": "**OpenAI Five (Deep RL game agent)**: Co-developed a superhuman Dota 2 bot using distributed deep reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) (multi-agent RL, gaming)."
      },
      "prefixrl_(circuit_design_via_rl)": {
        "id": "prefixrl_(circuit_design_via_rl)",
        "name": "PrefixRL (Circuit design via RL)",
        "type": "Project",
        "description": "**PrefixRL (Circuit design via RL)**: Introduced an RL approach to design parallel prefix circuits (e.g. adders, encoders) that Pareto-dominate baselines in area/delay ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)) (RL for hardware optimization)."
      },
      "llm_generative_ai_at_xai": {
        "id": "llm_generative_ai_at_xai",
        "name": "LLM/Generative AI at xAI",
        "type": "Project",
        "description": "**LLM/Generative AI at xAI**: Likely involved in building and deploying large-language-model\u2013based applications at xAI (no specific public details available)."
      },
      "agentic_ai_system_integration": {
        "id": "agentic_ai_system_integration",
        "name": "Agentic AI/System Integration",
        "type": "Project",
        "description": "**Agentic AI/System Integration**: Participated in development of agentic AI systems that use LLMs to perform multi-turn reasoning or tasks (specifics unpublished)."
      },
      "machine_learning_engineering": {
        "id": "machine_learning_engineering",
        "name": "Machine Learning Engineering",
        "type": "Project",
        "description": "**Machine Learning Engineering**: Contributed Python-based ML pipelines and feature engineering for AI services at xAI (project details not publicly documented)."
      },
      "openmoe_(icml_2024)**_\u2013_an_open": {
        "id": "openmoe_(icml_2024)**_\u2013_an_open",
        "name": "OpenMoE (ICML 2024)** \u2013 An open",
        "type": "Project",
        "description": "**OpenMoE (ICML 2024)** \u2013 An open-source mixture-of-experts language model framework that explores scalable LLM architectures ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) (LLM Training & Architecture)."
      },
      "mixeval_(neurips_2024)**_\u2013_a_benchmark_toolkit_that_combines_multiple_llm_test_sets_into_realistic_m": {
        "id": "mixeval_(neurips_2024)**_\u2013_a_benchmark_toolkit_that_combines_multiple_llm_test_sets_into_realistic_m",
        "name": "MixEval (NeurIPS 2024)** \u2013 A benchmark toolkit that combines multiple LLM test sets into realistic mixtures for more reliable evaluation ([xuefuzhao.github.io](https",
        "type": "Project",
        "description": "**MixEval (NeurIPS 2024)** \u2013 A benchmark toolkit that combines multiple LLM test sets into realistic mixtures for more reliable evaluation ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)) (Evaluation & Benchmarking)."
      },
      "longvila_(iclr_2025)**_\u2013_a_long": {
        "id": "longvila_(iclr_2025)**_\u2013_a_long",
        "name": "LongVILA (ICLR 2025)** \u2013 A long",
        "type": "Project",
        "description": "**LongVILA (ICLR 2025)** \u2013 A long-context visual language model for video understanding, extending LLMs to model very long videos ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) (Multimodal AI & Vision-Language)."
      },
      "cohere_rerank_(2023)**_\u2013_led_development_of_cohere\u2019s_rerank_system,_an_llm": {
        "id": "cohere_rerank_(2023)**_\u2013_led_development_of_cohere\u2019s_rerank_system,_an_llm",
        "name": "Cohere Rerank (2023)** \u2013 Led development of Cohere\u2019s Rerank system, an LLM",
        "type": "Project",
        "description": "**Cohere Rerank (2023)** \u2013 Led development of Cohere\u2019s Rerank system, an LLM-powered ranking model that orders search results by relevance, significantly improving enterprise search quality ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)) (LLMs/Evaluation)."
      },
      "rerank_3.5_upgrade_(2024)**_\u2013_advanced_the_rerank_model_to_version_3.5_with_better_reasoning_and_mul": {
        "id": "rerank_3.5_upgrade_(2024)**_\u2013_advanced_the_rerank_model_to_version_3.5_with_better_reasoning_and_mul",
        "name": "Rerank 3.5 Upgrade (2024)** \u2013 Advanced the Rerank model to version 3.5 with better reasoning and multilingual capabilities, enhancing complex query understanding and evaluation of RAG systems (LLMs/Evaluation).",
        "type": "Project",
        "description": "**Rerank 3.5 Upgrade (2024)** \u2013 Advanced the Rerank model to version 3.5 with better reasoning and multilingual capabilities, enhancing complex query understanding and evaluation of RAG systems (LLMs/Evaluation)."
      },
      "llm_pretraining_at_cohere**_\u2013_contributed_to_training_cohere\u2019s_large": {
        "id": "llm_pretraining_at_cohere**_\u2013_contributed_to_training_cohere\u2019s_large",
        "name": "LLM Pretraining at Cohere** \u2013 Contributed to training Cohere\u2019s large",
        "type": "Project",
        "description": "**LLM Pretraining at Cohere** \u2013 Contributed to training Cohere\u2019s large-scale language models (e.g. the new Aya series), optimizing model architecture, data pipelines, and pretraining strategies for improved performance on reasoning and generation tasks (LLMs)."
      },
      "devstral_(coding_agents)**_\u2013_a_24b": {
        "id": "devstral_(coding_agents)**_\u2013_a_24b",
        "name": "Devstral (Coding Agents)** \u2013 A 24B",
        "type": "Project",
        "description": "**Devstral (Coding Agents)** \u2013 A 24B-parameter agentic LLM fine-tuned for software engineering tasks (developed with All Hands AI). Devstral can explore and edit large codebases using tool interfaces and long contexts; it achieved 53.6% on the SWE-Bench coding benchmark (outperforming much larger models) ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)) ([www.techtarget.com](https://www.techtarget.com/searchenterpriseai/news/366624217/Mistral-AI-intros-Devstral-new-coding-LLM#:~:text=French%20AI%20startup%20Mistral%20AI,LLM%20for%20software%20engineering%20tasks))."
      },
      "pixtral_12b_(vision": {
        "id": "pixtral_12b_(vision",
        "name": "Pixtral 12B (Vision",
        "type": "Project",
        "description": "**Pixtral 12B (Vision-Language LLM)** \u2013 A multimodal 12B-parameter model integrating image and text understanding. Pixtral is designed to handle vision-and-language tasks effectively in a compact model, exploring how smaller LLMs can rival larger ones on visual-text benchmarks."
      },
      "voxtral_(audio": {
        "id": "voxtral_(audio",
        "name": "Voxtral (Audio",
        "type": "Project",
        "description": "**Voxtral (Audio-Text LLM)** \u2013 An audio-text multimodal LLM that jointly processes speech and language. Voxtral investigates unified models for hearing and reading, aiming to master audio comprehension and text generation tasks concurrently."
      },
      "magistral_(llm_reasoning_with_rl)": {
        "id": "magistral_(llm_reasoning_with_rl)",
        "name": "Magistral (LLM Reasoning with RL)",
        "type": "Project",
        "description": "**Magistral (LLM Reasoning with RL):** Led development of Magistral, Mistral AI\u2019s first reasoning-focused LLM, trained with a scalable reinforcement learning pipeline to enhance transparent chain-of-thought reasoning while preserving multimodal and instruction-following capabilities. (LLM Reasoning & RL)"
      },
      "voxtral_(multimodal_audio_chat)": {
        "id": "voxtral_(multimodal_audio_chat)",
        "name": "Voxtral (Multimodal Audio Chat)",
        "type": "Project",
        "description": "**Voxtral (Multimodal Audio Chat):** Co-authored Voxtral Mini and Small, state-of-the-art multimodal audio-chat models that process spoken audio and text, with a long-context window for up to 40min audio. Released new benchmarks for audio QA to measure speech understanding and knowledge retrieval. (Multimodal AI & Reasoning)"
      },
      "mode_(multi": {
        "id": "mode_(multi",
        "name": "MoDE (Multi",
        "type": "Project",
        "description": "**MoDE (Multi-task LLM Fine-Tuning):** Proposed Mixture of Dyadic Experts, a novel multi-task parameter-efficient fine-tuning method (PEFT) for LLMs that shares projection matrices and uses rank-1 adapters with routing. Demonstrated state-of-the-art on 700+ diverse tasks (Supernatural Instructions SNI benchmark). (LLM Training & Adaptation)"
      },
      "voxtral_&_magistral_(open": {
        "id": "voxtral_&_magistral_(open",
        "name": "Voxtral & Magistral (Open",
        "type": "Project",
        "description": "**Voxtral & Magistral (Open-Source LLMs):** Developed large-scale multimodal and reasoning-focused LLMs. Voxtral is a family of audio\u2013language models (3B\u2013123B parameters), and Magistral is an LLM line emphasizing chain-of-thought reasoning ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions))."
      },
      "agent_lumos_(acl_2024)": {
        "id": "agent_lumos_(acl_2024)",
        "name": "Agent Lumos (ACL 2024)",
        "type": "Project",
        "description": "**Agent Lumos (ACL 2024):** Introduced Lumos, a unified modular training framework for open-source language agents. Lumos learns high-level planning and grounding to tools, outperforming other open-source agents (and even GPT-4) on diverse tasks ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large))."
      },
      "rewardbench_(naacl_2025)": {
        "id": "rewardbench_(naacl_2025)",
        "name": "RewardBench (NAACL 2025)",
        "type": "Project",
        "description": "**RewardBench (NAACL 2025):** Created RewardBench, a benchmark dataset and codebase for evaluating language-model reward models used in RLHF. It analyzes reward-model behavior on structured queries, exposing issues in refusals, reasoning, and alignment ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the))."
      },
      "llm_deployment_optimization": {
        "id": "llm_deployment_optimization",
        "name": "LLM Deployment Optimization",
        "type": "Project",
        "description": "**LLM Deployment Optimization:** Developed techniques to improve LLM inference throughput (e.g., TensorRT-LLM optimizations) and reduce computational load, supporting NVIDIA\u2019s NeMo/Transformer toolchains for high-demand applications ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow))."
      },
      "automated_bidding_systems": {
        "id": "automated_bidding_systems",
        "name": "Automated Bidding Systems",
        "type": "Project",
        "description": "**Automated Bidding Systems:** Applied reinforcement learning and ML methods to optimize ad bidding strategies (target area: Reinforcement Learning & Agents), leveraging large-scale data from digital advertising to maximize ROI."
      },
      "recommender_system_modeling": {
        "id": "recommender_system_modeling",
        "name": "Recommender System Modeling",
        "type": "Project",
        "description": "**Recommender System Modeling:** Designed recommendation algorithms using neural networks and LLM embeddings to improve user targeting and relevance (target area: Multimodal AI & Vision-Language)."
      },
      "efficient_rlhf_reward_ensemble": {
        "id": "efficient_rlhf_reward_ensemble",
        "name": "Efficient RLHF Reward Ensemble",
        "type": "Project",
        "description": "**Efficient RLHF Reward Ensemble:** Developed ensemble-based reward models to improve the efficiency and alignment of reinforcement learning from human feedback ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment))."
      },
      "adaptive_replanning_with_diffusion_models": {
        "id": "adaptive_replanning_with_diffusion_models",
        "name": "Adaptive Replanning with Diffusion Models",
        "type": "Project",
        "description": "**Adaptive Replanning with Diffusion Models:** Introduced a method that uses diffusion-model-based planning to adaptively replan online, allowing agents to incorporate new observations during execution ([shunzh.github.io](https://shunzh.github.io/#:~:text=Conference%20on%20Neural%20Information%20Processing,planning))."
      }
    }
  },
  "edges": [
    {
      "source": "deep_learning",
      "relationship": "SPECIALIZATION_OF",
      "target": "machine_learning",
      "properties": {}
    },
    {
      "source": "reinforcement_learning",
      "relationship": "SPECIALIZATION_OF",
      "target": "machine_learning",
      "properties": {}
    },
    {
      "source": "supervised_learning",
      "relationship": "SPECIALIZATION_OF",
      "target": "machine_learning",
      "properties": {}
    },
    {
      "source": "neural_networks",
      "relationship": "SPECIALIZATION_OF",
      "target": "deep_learning",
      "properties": {}
    },
    {
      "source": "transformers",
      "relationship": "SPECIALIZATION_OF",
      "target": "deep_learning",
      "properties": {}
    },
    {
      "source": "cnns",
      "relationship": "SPECIALIZATION_OF",
      "target": "deep_learning",
      "properties": {}
    },
    {
      "source": "gpt_models",
      "relationship": "SPECIALIZATION_OF",
      "target": "llms",
      "properties": {}
    },
    {
      "source": "bert",
      "relationship": "SPECIALIZATION_OF",
      "target": "llms",
      "properties": {}
    },
    {
      "source": "training",
      "relationship": "SPECIALIZATION_OF",
      "target": "llms",
      "properties": {}
    },
    {
      "source": "fine_tuning",
      "relationship": "SPECIALIZATION_OF",
      "target": "llms",
      "properties": {}
    },
    {
      "source": "prompt_engineering",
      "relationship": "SPECIALIZATION_OF",
      "target": "llms",
      "properties": {}
    },
    {
      "source": "policy_optimization",
      "relationship": "SPECIALIZATION_OF",
      "target": "reinforcement_learning",
      "properties": {}
    },
    {
      "source": "q_learning",
      "relationship": "SPECIALIZATION_OF",
      "target": "reinforcement_learning",
      "properties": {}
    },
    {
      "source": "ppo",
      "relationship": "SPECIALIZATION_OF",
      "target": "reinforcement_learning",
      "properties": {}
    },
    {
      "source": "rlhf",
      "relationship": "SPECIALIZATION_OF",
      "target": "reinforcement_learning",
      "properties": {}
    },
    {
      "source": "vision_language",
      "relationship": "SPECIALIZATION_OF",
      "target": "multimodal_ai",
      "properties": {}
    },
    {
      "source": "audio_language",
      "relationship": "SPECIALIZATION_OF",
      "target": "multimodal_ai",
      "properties": {}
    },
    {
      "source": "cross_modal",
      "relationship": "SPECIALIZATION_OF",
      "target": "multimodal_ai",
      "properties": {}
    },
    {
      "source": "coding_agents",
      "relationship": "SPECIALIZATION_OF",
      "target": "code_generation",
      "properties": {}
    },
    {
      "source": "program_synthesis",
      "relationship": "SPECIALIZATION_OF",
      "target": "code_generation",
      "properties": {}
    },
    {
      "source": "code_completion",
      "relationship": "SPECIALIZATION_OF",
      "target": "code_generation",
      "properties": {}
    },
    {
      "source": "benchmarking",
      "relationship": "SPECIALIZATION_OF",
      "target": "evaluation",
      "properties": {}
    },
    {
      "source": "metrics",
      "relationship": "SPECIALIZATION_OF",
      "target": "evaluation",
      "properties": {}
    },
    {
      "source": "testing",
      "relationship": "SPECIALIZATION_OF",
      "target": "evaluation",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "WORKS_AT",
      "target": "nvidia",
      "properties": {
        "current": true
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "HAS_ROLE",
      "target": "ai_research:_co_creator_openai_five,_prefixrl,_deepspeech_2,_deepvoice_1,2,3,_deeptype_1,2,_chipnemo",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "HAS_SKILL",
      "target": "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "HAS_SKILL",
      "target": "large_scale_transformer_language_models_&_embeddings_(llm_training_and_representation)",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "HAS_SKILL",
      "target": "automated_code_generation_&_debugging_(llm_driven_coding_agents)",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "HAS_SKILL",
      "target": "ai_model_evaluation_&_benchmarking_(performance_optimization_and_comparisons)",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "jonathan_raiman",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)_&_large_scale_transfor",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "CONTRIBUTED_TO",
      "target": "openai_five_(deep_rl_game_agent)",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "CONTRIBUTED_TO",
      "target": "prefixrl_(circuit_design_via_rl)",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "AUTHORED",
      "target": "effective_large_language_model_debugging_with_best_first_tree_search_(arxiv,_2024,_0_citations)",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "AUTHORED",
      "target": "prefixrl:_optimization_of_parallel_prefix_circuits_using_deep_reinforcement_learning_(dac_2021,_5_ci",
      "properties": {}
    },
    {
      "source": "jonathan_raiman",
      "relationship": "AUTHORED",
      "target": "nv_embed:_improved_techniques_for_training_llms_as_generalist_embedding_models_(arxiv,_2024,_0_citat",
      "properties": {}
    },
    {
      "source": "deepa_nalla",
      "relationship": "WORKS_AT",
      "target": "xai",
      "properties": {
        "current": true
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "HAS_ROLE",
      "target": "ai_engineer_|_masters_graduate___business_analytics_and_ai__|_ex_deloitte_|_python_|_machine_learnin",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "HAS_SKILL",
      "target": "large_language_models_(llms)_and_generative_ai_systems",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "HAS_SKILL",
      "target": "autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_agents",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "HAS_SKILL",
      "target": "natural_language_processing_(nlp)_and_ai_driven_reasoning_pipelines",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "HAS_SKILL",
      "target": "machine_learning_model_development_and_api_deployment_for_ai",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "deepa_nalla",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "large_language_models_(llms)_and_generative_ai_systems_&_autonomous_\u201cagentic\u201d_ai_and_multi_step_ai_a",
      "properties": {}
    },
    {
      "source": "deepa_nalla",
      "relationship": "CONTRIBUTED_TO",
      "target": "llm_generative_ai_at_xai",
      "properties": {}
    },
    {
      "source": "deepa_nalla",
      "relationship": "CONTRIBUTED_TO",
      "target": "agentic_ai_system_integration",
      "properties": {}
    },
    {
      "source": "deepa_nalla",
      "relationship": "CONTRIBUTED_TO",
      "target": "machine_learning_engineering",
      "properties": {}
    },
    {
      "source": "deepa_nalla",
      "relationship": "AUTHORED",
      "target": "*no_known_publications_were_found_by_deepa_nalla_in_the_areas_of_llms,_multimodal_ai,_reinforcement_",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "WORKS_AT",
      "target": "google_deepmind",
      "properties": {
        "current": true
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "HAS_ROLE",
      "target": "large_language_model_researcher_|_homepage_(xuefuzhao.github.io)",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "HAS_SKILL",
      "target": "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "HAS_SKILL",
      "target": "transformer_sequence_efficiency_(elastic_dynamic_input_processing_during_training_and_inference)_([x",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "HAS_SKILL",
      "target": "multimodal_vision_and_language_modeling_(long_context_video_text_understanding,_unified_visual_token",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "HAS_SKILL",
      "target": "llm_evaluation_and_benchmarking_(real_world_mixture_based_benchmark_design)_([xuefuzhao.github.io](h",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "fuzhao_xue",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "CONTRIBUTED_TO",
      "target": "openmoe_(icml_2024)**_\u2013_an_open",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "CONTRIBUTED_TO",
      "target": "mixeval_(neurips_2024)**_\u2013_a_benchmark_toolkit_that_combines_multiple_llm_test_sets_into_realistic_m",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "CONTRIBUTED_TO",
      "target": "longvila_(iclr_2025)**_\u2013_a_long",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "AUTHORED",
      "target": "*openmoe:_an_early_effort_on_open_mixture_of_experts_language_models*_(icml_2024,_0_citations)",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "AUTHORED",
      "target": "*mixeval:_deriving_wisdom_of_the_crowd_from_llm_benchmark_mixtures*_(neurips_2024,_0_citations)",
      "properties": {}
    },
    {
      "source": "fuzhao_xue",
      "relationship": "AUTHORED",
      "target": "*longvila:_scaling_long_context_visual_language_models_for_long_videos*_(iclr_2025,_0_citations)",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "WORKS_AT",
      "target": "cohere",
      "properties": {
        "current": true
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "HAS_ROLE",
      "target": "llm_pre_training_at_cohere",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "HAS_SKILL",
      "target": "large_language_model_pre_training_and_architecture",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "HAS_SKILL",
      "target": "semantic_search_and_document_reranking_with_llms",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "HAS_SKILL",
      "target": "evaluation_and_benchmarking_of_nlp_models",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "HAS_SKILL",
      "target": "retrieval_augmented_generation_and_rag_systems",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "sylvie_shi",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "large_language_model_pre_training_and_architecture_&_semantic_search_and_document_reranking_with_llm",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "CONTRIBUTED_TO",
      "target": "cohere_rerank_(2023)**_\u2013_led_development_of_cohere\u2019s_rerank_system,_an_llm",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "CONTRIBUTED_TO",
      "target": "rerank_3.5_upgrade_(2024)**_\u2013_advanced_the_rerank_model_to_version_3.5_with_better_reasoning_and_mul",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "CONTRIBUTED_TO",
      "target": "llm_pretraining_at_cohere**_\u2013_contributed_to_training_cohere\u2019s_large",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "AUTHORED",
      "target": "*\u201ccohere_rerank:_enhancing_semantic_search_with_llms\u201d*_(cohere_blog,_2023,_0_citations)",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "AUTHORED",
      "target": "*\u201cintroducing_rerank_3.5:_precise_ai_search\u201d*_(cohere_blog,_2024,_0_citations)",
      "properties": {}
    },
    {
      "source": "sylvie_shi",
      "relationship": "AUTHORED",
      "target": "*\u201caya_23_8b:_a_multilingual_large_language_model_technical_report\u201d*_(cohere_technical_report,_2023,_",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "WORKS_AT",
      "target": "mistral_ai",
      "properties": {
        "current": true
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "HAS_ROLE",
      "target": "multimodal_llms_@_mistral_ai",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "HAS_SKILL",
      "target": "multimodal_vision_language_and_audio_language_modeling",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "HAS_SKILL",
      "target": "large_language_model_architecture_design_and_fine_tuning",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "HAS_SKILL",
      "target": "autonomous_coding_assistants_and_software_engineering_agents",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "HAS_SKILL",
      "target": "model_evaluation_and_robustness_(open_set_ood_detection)",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "sagar_vaze",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "multimodal_vision_language_and_audio_language_modeling_&_large_language_model_architecture_design_an",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "CONTRIBUTED_TO",
      "target": "devstral_(coding_agents)**_\u2013_a_24b",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "CONTRIBUTED_TO",
      "target": "pixtral_12b_(vision",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "CONTRIBUTED_TO",
      "target": "voxtral_(audio",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "AUTHORED",
      "target": "*devstral:_fine_tuning_language_models_for_coding_agent_applications*_(arxiv,_2025,_0_citations)",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "AUTHORED",
      "target": "*pixtral_12b:_can_a_smaller_model_punch_above_its_weight_in_vision_and_language_tasks?*_(arxiv,_2024",
      "properties": {}
    },
    {
      "source": "sagar_vaze",
      "relationship": "AUTHORED",
      "target": "*magistral:_can_mistral_out_reason_everyone_else_by_building_its_own_ai_learning_system?*_(arxiv,_20",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "WORKS_AT",
      "target": "mistral_ai",
      "properties": {
        "current": true
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "HAS_ROLE",
      "target": "research_scientist_at_mistral_ai_|_llm_reasoning",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "HAS_SKILL",
      "target": "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "HAS_SKILL",
      "target": "**reinforcement_learning_for_llm_reasoning**_(rlhf_pipelines_to_instill_chain_of_thought)",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "HAS_SKILL",
      "target": "**multimodal_conversational_models**_(audio+text_chat_ai_systems)",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "HAS_SKILL",
      "target": "**task_oriented_dialogue_systems**_(end_to_end_dialogue_agents_and_evaluation)",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)_&_**reinforcement_learni",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "CONTRIBUTED_TO",
      "target": "magistral_(llm_reasoning_with_rl)",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "CONTRIBUTED_TO",
      "target": "voxtral_(multimodal_audio_chat)",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "CONTRIBUTED_TO",
      "target": "mode_(multi",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "AUTHORED",
      "target": "**mode:_effective_multi_task_parameter_efficient_fine_tuning_with_a_mixture_of_dyadic_experts**_(fin",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "AUTHORED",
      "target": "**voxtral_mini_small:_multimodal_audio_chat_models**_(arxiv_2025,_0_citations)",
      "properties": {}
    },
    {
      "source": "abhinav_rastogi",
      "relationship": "AUTHORED",
      "target": "**magistral:_mistral\u2019s_first_reasoning_focused_llm**_(mistral_ai_research,_2025,_not_peer_reviewed)",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "WORKS_AT",
      "target": "mistral_ai",
      "properties": {
        "current": true
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "HAS_ROLE",
      "target": "ph.d,_multimodal_llms_@_mistral_ai_|_prev_@ai2,_meta,_google,_apple_|_ph.d._@cmu_|_rising_stars_@ucb",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "HAS_SKILL",
      "target": "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "HAS_SKILL",
      "target": "**llm_reasoning_&_chain_of_thought:**_developing_reasoning_architectures_and_chain_of_thought_techni",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "HAS_SKILL",
      "target": "**language_agent_architectures:**_building_and_training_open_source_llm_based_agents_with_modular_pl",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "HAS_SKILL",
      "target": "**evaluation_&_uncertainty_metrics:**_creating_benchmarks_and_metrics_to_evaluate_model_behavior,_su",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "khyathi_chandu",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "CONTRIBUTED_TO",
      "target": "voxtral_&_magistral_(open",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "CONTRIBUTED_TO",
      "target": "agent_lumos_(acl_2024)",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "CONTRIBUTED_TO",
      "target": "rewardbench_(naacl_2025)",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "AUTHORED",
      "target": "*agent_lumos:_unified_and_modular_training_for_open_source_language_agents*_(acl_2024,_3_citations)_",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "AUTHORED",
      "target": "*certainly_uncertain:_a_benchmark_and_metric_for_multimodal_epistemic_and_aleatoric_awareness*_(arxi",
      "properties": {}
    },
    {
      "source": "khyathi_chandu",
      "relationship": "AUTHORED",
      "target": "*rewardbench:_evaluating_reward_models_for_language_modeling*_(naacl_2025,_0_citations)_([aclantholo",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "WORKS_AT",
      "target": "nvidia",
      "properties": {
        "current": true
      }
    },
    {
      "source": "shangda_li",
      "relationship": "HAS_ROLE",
      "target": "large_language_model,_machine_learning,_ads_automated_bidding,_recommender_system.",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "shangda_li",
      "relationship": "HAS_SKILL",
      "target": "large_language_model_development_and_tuning",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "shangda_li",
      "relationship": "HAS_SKILL",
      "target": "machine_learning_for_ads_optimization_and_recommender_systems",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "shangda_li",
      "relationship": "HAS_SKILL",
      "target": "model_evaluation_and_benchmarking_(especially_llm_performance)",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "shangda_li",
      "relationship": "HAS_SKILL",
      "target": "practical_deployment_of_ml_rl_techniques_in_industry_settings",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "shangda_li",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "CONTRIBUTED_TO",
      "target": "llm_deployment_optimization",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "CONTRIBUTED_TO",
      "target": "automated_bidding_systems",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "CONTRIBUTED_TO",
      "target": "recommender_system_modeling",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "AUTHORED",
      "target": "*\u201ctfg_flow:_training_free_guidance_in_multimodal_generative_flow\u201d*_(icml_workshop,_2025)_\u2013_training_",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "AUTHORED",
      "target": "*\u201cfunctional_interpolation_for_relative_positions_improves_long_context_transformers\u201d*_(iclr,_2023)_",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "AUTHORED",
      "target": "*\u201cstable,_fast_and_accurate:_kernelized_attention_with_relative_positional_encoding\u201d*_(neurips,_2021",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "WORKS_AT",
      "target": "nvidia",
      "properties": {
        "current": true
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "HAS_ROLE",
      "target": "embodied_ai_+_reasoning_@_nvidia",
      "properties": {
        "seniority": "mid"
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "HAS_SKILL",
      "target": "reinforcement_learning_(policy_optimization,_safe_adaptive_rl)",
      "properties": {
        "proficiency": "expert",
        "rank": 1
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "HAS_SKILL",
      "target": "large_language_models_(llm_based_planning_and_code_generation)",
      "properties": {
        "proficiency": "expert",
        "rank": 2
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "HAS_SKILL",
      "target": "generative_models_for_sequential_decision_making_(diffusion_planning,_transformer_reasoning)",
      "properties": {
        "proficiency": "advanced",
        "rank": 3
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "HAS_SKILL",
      "target": "reward_modeling_and_value_alignment_(rl_from_human_feedback,_ensemble_reward_models)",
      "properties": {
        "proficiency": "advanced",
        "rank": 4
      }
    },
    {
      "source": "shun_zhang",
      "relationship": "BELONGS_TO_CLUSTER",
      "target": "large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "CONTRIBUTED_TO",
      "target": "efficient_rlhf_reward_ensemble",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "CONTRIBUTED_TO",
      "target": "adaptive_replanning_with_diffusion_models",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "AUTHORED",
      "target": "*adaptive_online_replanning_with_diffusion_models*_(neurips,_2023;_~3_citations)_([shunzh.github.io]",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "AUTHORED",
      "target": "*planning_with_large_language_models_for_code_generation*_(iclr,_2023;_~10_citations)_([shunzh.githu",
      "properties": {}
    },
    {
      "source": "shun_zhang",
      "relationship": "AUTHORED",
      "target": "*improving_reinforcement_learning_from_human_feedback_with_efficient_reward_model_ensemble*_(arxiv,_",
      "properties": {}
    },
    {
      "source": "shangda_li",
      "relationship": "SIMILAR_TO",
      "target": "shun_zhang",
      "properties": {
        "skill_similarity": 0.0,
        "shared_cluster": true
      }
    }
  ],
  "statistics": {
    "total_nodes": 146,
    "total_edges": 138,
    "node_counts": {
      "Person": 9,
      "Skill": 65,
      "Company": 5,
      "Role": 9,
      "Publication": 25,
      "ResearchCluster": 8,
      "Project": 25
    }
  }
}