cluster_id,cluster_name,num_researchers,top_expertise,example_members
0,"Reinforcement Learning & Multi-Agent Systems (Game Ai, Hardware Optimization) & Large-Scale Transformer Language Models & Embeddings (Llm Training And Representation) & Automated Code Generation & Debugging (Llm-Driven Coding Agents)",1,"reinforcement learning & multi-agent systems (game ai, hardware optimization), large-scale transformer language models & embeddings (llm training and representation), automated code generation & debugging (llm-driven coding agents)",Jonathan Raiman
1,Large Language Model Development And Tuning & Machine Learning For Ads Optimization And Recommender Systems & Model Evaluation And Benchmarking (Especially Llm Performance),2,"large language model development and tuning, machine learning for ads optimization and recommender systems, model evaluation and benchmarking (especially llm performance)","Shangda Li, Shun Zhang"
2,Multimodal Vision-Language And Audio-Language Modeling & Large Language Model Architecture Design And Fine-Tuning & Autonomous Coding Assistants And Software Engineering Agents,1,"multimodal vision-language and audio-language modeling, large language model architecture design and fine-tuning, autonomous coding assistants and software engineering agents",Sagar Vaze
3,Large Language Models (Llms) And Generative Ai Systems & Autonomous “Agentic” Ai And Multi-Step Ai Agents & Natural Language Processing (Nlp) And Ai-Driven Reasoning Pipelines,1,"large language models (llms) and generative ai systems, autonomous “agentic” ai and multi-step ai agents, natural language processing (nlp) and ai-driven reasoning pipelines",Deepa Nalla
4,Large Language Model Pre-Training And Architecture & Semantic Search And Document Reranking With Llms & Evaluation And Benchmarking Of Nlp Models,1,"large language model pre-training and architecture, semantic search and document reranking with llms, evaluation and benchmarking of nlp models",Sylvie Shi
5,"Large-Scale Llm Architecture And Scaling (Efficient Pretraining, Mixture-Of-Experts Models) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=I%E2%80%99M%20A%20Senior%20Research%20Scientist,And%20Multimodal%20Research%20For%20Gemini)) & Transformer Sequence Efficiency (Elastic/Dynamic Input Processing During Training And Inference) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=,Icml%29%202023)) & Multimodal Vision-And-Language Modeling (Long-Context Video-Text Understanding, Unified Visual Tokenizers) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/Publications/#:~:Text=%2A%20Longvila%3A%20Scaling%20Long,Indicates))",1,"large-scale llm architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=i%e2%80%99m%20a%20senior%20research%20scientist,and%20multimodal%20research%20for%20gemini)), transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,icml%29%202023)), multimodal vision-and-language modeling (long-context video-text understanding, unified visual tokenizers) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2a%20longvila%3a%20scaling%20long,indicates))",Fuzhao Xue
6,"**Multimodal Language Models:** Designing And Training Large-Scale Language Models That Integrate Audio And Visual Information (E.G. Open-Source Audio–Language “Voxtral” Models) ([Khyathiraghavi.Github.Io](Https://Khyathiraghavi.Github.Io/#:~:Text=My%20Research%20Centers%20On%20Developing,Focus%20On%20Two%20Key%20Directions)). & **Llm Reasoning & Chain-Of-Thought:** Developing Reasoning Architectures And Chain-Of-Thought Techniques For Llms (E.G. “Magistral” Models For Long-Form Reasoning). & **Language-Agent Architectures:** Building And Training Open-Source Llm-Based Agents With Modular Planning And Execution Components (E.G. The Lumos Framework For Interactive Tasks) ([Aclanthology.Org](Https://Aclanthology.Org/People/Khyathi-Chandu/#:~:Text=Closed,Agent%20Learning%2C%20We%20Collect%20Large)).",1,"**multimodal language models:** designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio–language “voxtral” models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=my%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions))., **llm reasoning & chain-of-thought:** developing reasoning architectures and chain-of-thought techniques for llms (e.g. “magistral” models for long-form reasoning)., **language-agent architectures:** building and training open-source llm-based agents with modular planning and execution components (e.g. the lumos framework for interactive tasks) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=closed,agent%20learning%2c%20we%20collect%20large)).",Khyathi Chandu
7,**Llm Fine-Tuning & Adaptation** (Peft/Lora Techniques For Multi-Task Llms) & **Reinforcement Learning For Llm Reasoning** (Rlhf Pipelines To Instill Chain-Of-Thought) & **Multimodal Conversational Models** (Audio+Text Chat Ai Systems),1,"**llm fine-tuning & adaptation** (peft/lora techniques for multi-task llms), **reinforcement learning for llm reasoning** (rlhf pipelines to instill chain-of-thought), **multimodal conversational models** (audio+text chat ai systems)",Abhinav Rastogi
