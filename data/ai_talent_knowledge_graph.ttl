@prefix : <http://talent.ai/ontology#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

:jonathan_raiman a :Person ;
    :name "Jonathan Raiman" ;
    :title "AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, DeepType 1,2, Chipnemo" ;
    :summary "Jonathan Raiman is a research scientist whose work focuses on large-scale generative language models and distributed reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=Jonathan%20Raiman%20is%20a%20senior,Deep%20Voice%201%2C%202%2C%20and)). He has co-created superhuman RL systems (e.g. OpenAI Five) and led projects to improve LLM capacities such as embedding training and code-debugging techniques." ;
    :linkedin_url "https://www.linkedin.com/in/jonathanraiman" ;
    :impact "Raiman’s work has demonstrated the power of RL in complex domains (e.g. game-playing and circuit design), setting new benchmarks in multi-agent learning and hardware optimization ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)).  His LLM-focused research on e" ;
    :analyzed_at "2025-11-23T13:57:00.352443" ;
    .

:deepa_nalla a :Person ;
    :name "Deepa Nalla" ;
    :title "AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Python | Machine Learning | GenAI | LLMs | API Development | Agentic AI | Feature Engineering | AWS Certified" ;
    :summary "Deepa Nalla is an AI Engineering professional working at xAI, with a focus on large language models and generative AI systems.  However, there is no publicly documented research output or known academic work by her in LLMs, multimodal learning, reinforcement learning, model evaluation, reasoning, or coding agents." ;
    :linkedin_url "https://www.linkedin.com/in/deepa-nalla-046b70200" ;
    :impact "Since Deepa Nalla’s work appears to be industry-focused rather than academic, her direct impact on LLM research, multimodal AI, RL/agents, benchmarks, reasoning, or coding agents is not evident from the public record. Any influence is likely through applied system development at xAI (e.g. integrating LLMs into products), rather than through known research innovations or published benchmarks." ;
    :analyzed_at "2025-11-23T14:04:16.221660" ;
    .

:fuzhao_xue a :Person ;
    :name "Fuzhao Xue" ;
    :title "Large Language Model Researcher | HomePage (xuefuzhao.github.io)" ;
    :summary "Fuzhao Xue is a Senior Research Scientist at Google DeepMind whose recent work centers on efficient large language model pretraining (model architecture and scaling) and multimodal foundation models ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)). His research spans LLM optimization (e.g. mixture-of-experts, adaptive sequence handling) and vision-language modeling (long-context video LLMs for" ;
    :linkedin_url "https://www.linkedin.com/in/fuzhao-xue-6410561a6" ;
    :google_scholar "https://scholar.google.com/scholar?q=Fuzhao+Xue" ;
    :impact "Xue’s work has advanced large-model design and training. For LLMs, his Mixture-of-Experts (OpenMoE) and dynamic-sequence approaches improve model efficiency and scalability ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023)). In multimodal AI, his LongVILA video-language model (and related “Wolf” summarization work) pushes the boundary of LLMs to understand long video context ([xuefuzhao.githu" ;
    :analyzed_at "2025-11-23T14:17:21.104933" ;
    .

:sylvie_shi a :Person ;
    :name "Sylvie Shi" ;
    :title "LLM Pre-training at Cohere" ;
    :summary "Sylvie Shi is an AI researcher at Cohere focused on large language model (LLM) pre-training and improving semantic search via LLM-based reranking ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her work spans building and fine-tuning Cohere’s LLM architectures and developing tools like the Cohere Rerank model to boost search result relevance." ;
    :linkedin_url "https://www.linkedin.com/in/sylvie-shi-891792107" ;
    :impact "Sylvie Shi’s work has pushed forward Cohere’s LLM capabilities and search technologies. By leading LLM pretraining efforts and building the Rerank model, she has improved how LLMs are scaled and evaluated for retrieval tasks ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her contributions have strengthened the bridge between foundational LLM research and practical applications in semantic search and knowledge retrieval." ;
    :analyzed_at "2025-11-23T14:24:52.694096" ;
    .

:sagar_vaze a :Person ;
    :name "Sagar Vaze" ;
    :title "Multimodal LLMs @ Mistral AI" ;
    :summary "Sagar Vaze is a research scientist at Mistral AI who focuses on developing and fine-tuning large multimodal language models and intelligent agents. His work centers on integrating vision, audio, and code into LLM frameworks and advancing model reasoning and evaluation." ;
    :linkedin_url "https://www.linkedin.com/in/sagar-vaze-2356ab171" ;
    :impact "Sagar’s contributions have advanced practical LLM capabilities in multiple domains. For example, his Devstral model showed that a relatively small (24B) LLM can outperform much larger models on software engineering tasks ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)), demonstrating the power of specialized coding agents. He has also supported the integration of tools and modalities into LLM workflows (e.g. Mistral’s agent API with connectors for code ex" ;
    :analyzed_at "2025-11-23T14:29:39.269097" ;
    .

:abhinav_rastogi a :Person ;
    :name "Abhinav Rastogi" ;
    :title "Research Scientist at Mistral AI | LLM Reasoning" ;
    :summary "Abhinav Rastogi’s work centers on advancing reasoning and adaptability in large language models, leveraging reinforcement learning and novel fine-tuning methods. He also develops multimodal conversational AI (especially audio-based chat) and end-to-end task-oriented dialogue systems." ;
    :linkedin_url "https://www.linkedin.com/in/abhi-rast" ;
    :impact "Rastogi has pushed the boundaries of LLM reasoning by developing a fully custom RL training stack (Magistral) that produces open-source reasoning-capable models, demonstrating that language-model-based RL can improve chain-of-thought without sacrificing base capabilities. His multimodal Voxtral models advance vision-language AI into the audio domain with long-context comprehension. Through MoDE and related work, he has improved how large models are fine-tuned across many tasks efficiently. Overa" ;
    :analyzed_at "2025-11-23T14:31:26.697013" ;
    .

:khyathi_chandu a :Person ;
    :name "Khyathi Chandu" ;
    :title "Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU | Rising Stars @UCB 2020" ;
    :summary "Khyathi Chandu’s research centers on developing and training large-scale multimodal language models (e.g. audio–language LLMs) and improving reasoning capabilities in LLM-based agents ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)). She also focuses on rigorous evaluation and benchmarking of these models, including uncertainty metrics and reward-model assessments for improved alignment ([hugging" ;
    :linkedin_url "https://www.linkedin.com/in/khyathi-chandu-22871877" ;
    :google_scholar "https://scholar.google.com/scholar?q=Khyathi+Chandu" ;
    :impact "Chandu has significantly advanced open research in large-scale multimodal and reasoning models, and in the development of evaluation frameworks for LLMs. Her work on benchmarks like CertainlyUncertain and RewardBench provides new tools to assess model uncertainty and alignment, directly impacting the reliability of vision–language and RLHF systems ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology." ;
    :analyzed_at "2025-11-23T14:34:47.040725" ;
    .

:shangda_li a :Person ;
    :name "Shangda Li" ;
    :title "Large Language Model, Machine Learning, Ads Automated Bidding, Recommender System." ;
    :summary "Shangda Li’s work centers on applying large language models (LLMs) and machine learning techniques to practical domains such as advertising and recommendation, focusing on model training, evaluation, and inference efficiencies." ;
    :linkedin_url "https://www.linkedin.com/in/shangda-harry-li-7a822410a" ;
    :impact "Li’s work has improved the efficiency and applicability of LLMs in industry, both by optimizing model architectures and by integrating LLMs into real-world systems (ads and recsys). His focus on evaluation and benchmarks helps ensure robustness of models in practice, and his contributions to reasoning frameworks and code agents advance LLM capabilities. Li’s collaborations on NVIDIA’s NeMo and related projects have driven both theoretical and practical advances in model deployment and agent-driv" ;
    :analyzed_at "2025-11-23T14:36:22.479520" ;
    .

:shun_zhang a :Person ;
    :name "Shun Zhang" ;
    :title "Embodied AI + Reasoning @ NVIDIA" ;
    :summary "Shun Zhang’s work bridges reinforcement learning and large language models ([shunzh.github.io](https://shunzh.github.io/#:~:text=Hi%21%20This%20is%20Shun%20Zhang,from%20the%20University%20of%20Michigan)). He focuses on using generative models (like diffusion models and LLMs) for planning and reasoning, including applications in code generation and human-aligned RL." ;
    :linkedin_url "https://www.linkedin.com/in/shun-zhang-1b154437" ;
    :impact "Shun Zhang’s research has advanced the integration of LLMs into agent decision-making. His reward model ensemble work makes RLHF training more computationally efficient and aligned with human values ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment)). By using LLMs to guide search, his code-generation planner boosts the capabilities of coding agents ([shunzh.github.io](https://shunzh.github.io/#:~:text=%5Bcode%5D%20Our%20algorithm%20combines%20Monte,plann" ;
    :analyzed_at "2025-11-23T14:46:00.334810" ;
    .

:machine_learning a :Skill ;
    :name "Machine Learning" ;
    .

:deep_learning a :Skill ;
    :name "Deep Learning" ;
    .

:reinforcement_learning a :Skill ;
    :name "Reinforcement Learning" ;
    .

:supervised_learning a :Skill ;
    :name "Supervised Learning" ;
    .

:neural_networks a :Skill ;
    :name "Neural Networks" ;
    .

:transformers a :Skill ;
    :name "Transformers" ;
    .

:cnns a :Skill ;
    :name "CNNs" ;
    .

:llms a :Skill ;
    :name "LLMs" ;
    .

:gpt_models a :Skill ;
    :name "GPT Models" ;
    .

:bert a :Skill ;
    :name "BERT" ;
    .

:training a :Skill ;
    :name "Training" ;
    .

:fine_tuning a :Skill ;
    :name "Fine-tuning" ;
    .

:prompt_engineering a :Skill ;
    :name "Prompt Engineering" ;
    .

:policy_optimization a :Skill ;
    :name "Policy Optimization" ;
    .

:q_learning a :Skill ;
    :name "Q-Learning" ;
    .

:ppo a :Skill ;
    :name "PPO" ;
    .

:rlhf a :Skill ;
    :name "RLHF" ;
    .

:multimodal_ai a :Skill ;
    :name "Multimodal AI" ;
    .

:vision_language a :Skill ;
    :name "Vision-Language" ;
    .

:audio_language a :Skill ;
    :name "Audio-Language" ;
    .

:cross_modal a :Skill ;
    :name "Cross-Modal" ;
    .

:code_generation a :Skill ;
    :name "Code Generation" ;
    .

:coding_agents a :Skill ;
    :name "Coding Agents" ;
    .

:program_synthesis a :Skill ;
    :name "Program Synthesis" ;
    .

:code_completion a :Skill ;
    :name "Code Completion" ;
    .

:evaluation a :Skill ;
    :name "Evaluation" ;
    .

:benchmarking a :Skill ;
    :name "Benchmarking" ;
    .

:metrics a :Skill ;
    :name "Metrics" ;
    .

:testing a :Skill ;
    :name "Testing" ;
    .

:reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization) a :Skill ;
    :name "Reinforcement Learning & Multi-Agent Systems (game AI, hardware optimization)" ;
    .

:large_scale_transformer_language_models_&_embeddings_(llm_training_and_representation) a :Skill ;
    :name "Large-Scale Transformer Language Models & Embeddings (LLM training and representation)" ;
    .

:automated_code_generation_&_debugging_(llm_driven_coding_agents) a :Skill ;
    :name "Automated Code Generation & Debugging (LLM-driven coding agents)" ;
    .

:ai_model_evaluation_&_benchmarking_(performance_optimization_and_comparisons) a :Skill ;
    :name "AI Model Evaluation & Benchmarking (performance optimization and comparisons)" ;
    .

:large_language_models_(llms)_and_generative_ai_systems a :Skill ;
    :name "Large Language Models (LLMs) and Generative AI systems" ;
    .

:autonomous_“agentic”_ai_and_multi_step_ai_agents a :Skill ;
    :name "Autonomous “agentic” AI and multi-step AI agents" ;
    .

:natural_language_processing_(nlp)_and_ai_driven_reasoning_pipelines a :Skill ;
    :name "Natural Language Processing (NLP) and AI-driven reasoning pipelines" ;
    .

:machine_learning_model_development_and_api_deployment_for_ai a :Skill ;
    :name "Machine Learning model development and API deployment for AI" ;
    .

:large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz a :Skill ;
    :name "Large-scale LLM architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini))" ;
    .

:transformer_sequence_efficiency_(elastic_dynamic_input_processing_during_training_and_inference)_([x a :Skill ;
    :name "Transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023))" ;
    .

:multimodal_vision_and_language_modeling_(long_context_video_text_understanding,_unified_visual_token a :Skill ;
    :name "Multimodal vision-and-language modeling (long-context video-text understanding, unified visual tokenizers) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates))" ;
    .

:llm_evaluation_and_benchmarking_(real_world_mixture_based_benchmark_design)_([xuefuzhao.github.io](h a :Skill ;
    :name "LLM evaluation and benchmarking (real-world mixture-based benchmark design) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024))" ;
    .

:large_language_model_pre_training_and_architecture a :Skill ;
    :name "Large Language Model Pre-training and Architecture" ;
    .

:semantic_search_and_document_reranking_with_llms a :Skill ;
    :name "Semantic Search and Document Reranking with LLMs" ;
    .

:evaluation_and_benchmarking_of_nlp_models a :Skill ;
    :name "Evaluation and Benchmarking of NLP Models" ;
    .

:retrieval_augmented_generation_and_rag_systems a :Skill ;
    :name "Retrieval-Augmented Generation and RAG Systems" ;
    .

:multimodal_vision_language_and_audio_language_modeling a :Skill ;
    :name "Multimodal vision-language and audio-language modeling" ;
    .

:large_language_model_architecture_design_and_fine_tuning a :Skill ;
    :name "Large language model architecture design and fine-tuning" ;
    .

:autonomous_coding_assistants_and_software_engineering_agents a :Skill ;
    :name "Autonomous coding assistants and software engineering agents" ;
    .

:model_evaluation_and_robustness_(open_set_ood_detection) a :Skill ;
    :name "Model evaluation and robustness (open-set/OOD detection)" ;
    .

:**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms) a :Skill ;
    :name "**LLM Fine-tuning & Adaptation** (PEFT/LoRA techniques for multi-task LLMs)" ;
    .

:**reinforcement_learning_for_llm_reasoning**_(rlhf_pipelines_to_instill_chain_of_thought) a :Skill ;
    :name "**Reinforcement Learning for LLM Reasoning** (RLHF pipelines to instill chain-of-thought)" ;
    .

:**multimodal_conversational_models**_(audio+text_chat_ai_systems) a :Skill ;
    :name "**Multimodal Conversational Models** (audio+text chat AI systems)" ;
    .

:**task_oriented_dialogue_systems**_(end_to_end_dialogue_agents_and_evaluation) a :Skill ;
    :name "**Task-Oriented Dialogue Systems** (end-to-end dialogue agents and evaluation)" ;
    .

:**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au a :Skill ;
    :name "**Multimodal Language Models:** Designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio–language “Voxtral” models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions))." ;
    .

:**llm_reasoning_&_chain_of_thought:**_developing_reasoning_architectures_and_chain_of_thought_techni a :Skill ;
    :name "**LLM Reasoning & Chain-of-Thought:** Developing reasoning architectures and chain-of-thought techniques for LLMs (e.g. “Magistral” models for long-form reasoning)." ;
    .

:**language_agent_architectures:**_building_and_training_open_source_llm_based_agents_with_modular_pl a :Skill ;
    :name "**Language-Agent Architectures:** Building and training open-source LLM-based agents with modular planning and execution components (e.g. the Lumos framework for interactive tasks) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large))." ;
    .

:**evaluation_&_uncertainty_metrics:**_creating_benchmarks_and_metrics_to_evaluate_model_behavior,_su a :Skill ;
    :name "**Evaluation & Uncertainty Metrics:** Creating benchmarks and metrics to evaluate model behavior, such as RLHF reward-model evaluation (RewardBench) and multimodal uncertainty detection (e.g. CertainlyUncertain for VQA) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%2" ;
    .

:large_language_model_development_and_tuning a :Skill ;
    :name "Large Language Model development and tuning" ;
    .

:machine_learning_for_ads_optimization_and_recommender_systems a :Skill ;
    :name "Machine Learning for Ads optimization and Recommender Systems" ;
    .

:model_evaluation_and_benchmarking_(especially_llm_performance) a :Skill ;
    :name "Model evaluation and benchmarking (especially LLM performance)" ;
    .

:practical_deployment_of_ml_rl_techniques_in_industry_settings a :Skill ;
    :name "Practical deployment of ML/RL techniques in industry settings" ;
    .

:reinforcement_learning_(policy_optimization,_safe_adaptive_rl) a :Skill ;
    :name "Reinforcement Learning (policy optimization, safe/adaptive RL)" ;
    .

:large_language_models_(llm_based_planning_and_code_generation) a :Skill ;
    :name "Large Language Models (LLM-based planning and code generation)" ;
    .

:generative_models_for_sequential_decision_making_(diffusion_planning,_transformer_reasoning) a :Skill ;
    :name "Generative Models for Sequential Decision-Making (diffusion planning, transformer reasoning)" ;
    .

:reward_modeling_and_value_alignment_(rl_from_human_feedback,_ensemble_reward_models) a :Skill ;
    :name "Reward Modeling and Value Alignment (RL from human feedback, ensemble reward models)" ;
    .

:nvidia a :Company ;
    :name "NVIDIA" ;
    .

:xai a :Company ;
    :name "xAI" ;
    .

:google_deepmind a :Company ;
    :name "Google DeepMind" ;
    .

:cohere a :Company ;
    :name "Cohere" ;
    .

:mistral_ai a :Company ;
    :name "Mistral AI" ;
    .

:ai_research:_co_creator_openai_five,_prefixrl,_deepspeech_2,_deepvoice_1,2,3,_deeptype_1,2,_chipnemo a :Role ;
    :title "AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, DeepType 1,2, Chipnemo" ;
    :seniority "mid" ;
    .

:ai_engineer_|_masters_graduate___business_analytics_and_ai__|_ex_deloitte_|_python_|_machine_learnin a :Role ;
    :title "AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Python | Machine Learning | GenAI | LLMs | API Development | Agentic AI | Feature Engineering | AWS Certified" ;
    :seniority "mid" ;
    .

:large_language_model_researcher_|_homepage_(xuefuzhao.github.io) a :Role ;
    :title "Large Language Model Researcher | HomePage (xuefuzhao.github.io)" ;
    :seniority "mid" ;
    .

:llm_pre_training_at_cohere a :Role ;
    :title "LLM Pre-training at Cohere" ;
    :seniority "mid" ;
    .

:multimodal_llms_@_mistral_ai a :Role ;
    :title "Multimodal LLMs @ Mistral AI" ;
    :seniority "mid" ;
    .

:research_scientist_at_mistral_ai_|_llm_reasoning a :Role ;
    :title "Research Scientist at Mistral AI | LLM Reasoning" ;
    :seniority "mid" ;
    .

:ph.d,_multimodal_llms_@_mistral_ai_|_prev_@ai2,_meta,_google,_apple_|_ph.d._@cmu_|_rising_stars_@ucb a :Role ;
    :title "Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU | Rising Stars @UCB 2020" ;
    :seniority "mid" ;
    .

:large_language_model,_machine_learning,_ads_automated_bidding,_recommender_system. a :Role ;
    :title "Large Language Model, Machine Learning, Ads Automated Bidding, Recommender System." ;
    :seniority "mid" ;
    .

:embodied_ai_+_reasoning_@_nvidia a :Role ;
    :title "Embodied AI + Reasoning @ NVIDIA" ;
    :seniority "mid" ;
    .

:effective_large_language_model_debugging_with_best_first_tree_search_(arxiv,_2024,_0_citations) a :Publication ;
    :title "Effective Large Language Model Debugging with Best-First Tree Search (arXiv, 2024, 0 citations)" ;
    .

:prefixrl:_optimization_of_parallel_prefix_circuits_using_deep_reinforcement_learning_(dac_2021,_5_ci a :Publication ;
    :title "PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning (DAC 2021, 5 citations)" ;
    .

:nv_embed:_improved_techniques_for_training_llms_as_generalist_embedding_models_(arxiv,_2024,_0_citat a :Publication ;
    :title "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models (arXiv, 2024, 0 citations)" ;
    .

:*no_known_publications_were_found_by_deepa_nalla_in_the_areas_of_llms,_multimodal_ai,_reinforcement_ a :Publication ;
    :title "*No known publications were found by Deepa Nalla in the areas of LLMs, multimodal AI, reinforcement learning, reasoning, or AI coding agents.*" ;
    .

:*openmoe:_an_early_effort_on_open_mixture_of_experts_language_models*_(icml_2024,_0_citations) a :Publication ;
    :title "*OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models* (ICML 2024, 0 citations)" ;
    .

:*mixeval:_deriving_wisdom_of_the_crowd_from_llm_benchmark_mixtures*_(neurips_2024,_0_citations) a :Publication ;
    :title "*MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures* (NeurIPS 2024, 0 citations)" ;
    .

:*longvila:_scaling_long_context_visual_language_models_for_long_videos*_(iclr_2025,_0_citations) a :Publication ;
    :title "*LongVILA: Scaling Long-Context Visual Language Models for Long Videos* (ICLR 2025, 0 citations)" ;
    .

:*“cohere_rerank:_enhancing_semantic_search_with_llms”*_(cohere_blog,_2023,_0_citations) a :Publication ;
    :title "*“Cohere Rerank: Enhancing Semantic Search with LLMs”* (Cohere Blog, 2023, 0 citations)" ;
    .

:*“introducing_rerank_3.5:_precise_ai_search”*_(cohere_blog,_2024,_0_citations) a :Publication ;
    :title "*“Introducing Rerank 3.5: Precise AI Search”* (Cohere Blog, 2024, 0 citations)" ;
    .

:*“aya_23_8b:_a_multilingual_large_language_model_technical_report”*_(cohere_technical_report,_2023,_ a :Publication ;
    :title "*“Aya 23-8B: A Multilingual Large Language Model Technical Report”* (Cohere Technical Report, 2023, 0 citations)" ;
    .

:*devstral:_fine_tuning_language_models_for_coding_agent_applications*_(arxiv,_2025,_0_citations) a :Publication ;
    :title "*DevStral: Fine-tuning Language Models for Coding Agent Applications* (arXiv, 2025, 0 citations)" ;
    .

:*pixtral_12b:_can_a_smaller_model_punch_above_its_weight_in_vision_and_language_tasks?*_(arxiv,_2024 a :Publication ;
    :title "*Pixtral 12B: Can a Smaller Model Punch Above its Weight in Vision-and-Language Tasks?* (arXiv, 2024, 0 citations)" ;
    .

:*magistral:_can_mistral_out_reason_everyone_else_by_building_its_own_ai_learning_system?*_(arxiv,_20 a :Publication ;
    :title "*Magistral: Can Mistral Out-Reason Everyone Else by Building Its Own AI Learning System?* (arXiv, 2025, 0 citations)" ;
    .

:**mode:_effective_multi_task_parameter_efficient_fine_tuning_with_a_mixture_of_dyadic_experts**_(fin a :Publication ;
    :title "**MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a Mixture of Dyadic Experts** (Findings of ACL: NAACL 2025, 0 citations)" ;
    .

:**voxtral_mini_small:_multimodal_audio_chat_models**_(arxiv_2025,_0_citations) a :Publication ;
    :title "**Voxtral Mini/Small: Multimodal Audio-Chat Models** (ArXiv 2025, 0 citations)" ;
    .

:**magistral:_mistral’s_first_reasoning_focused_llm**_(mistral_ai_research,_2025,_not_peer_reviewed) a :Publication ;
    :title "**Magistral: Mistral’s First Reasoning-Focused LLM** (Mistral AI Research, 2025, not peer-reviewed)" ;
    .

:*agent_lumos:_unified_and_modular_training_for_open_source_language_agents*_(acl_2024,_3_citations)_ a :Publication ;
    :title "*Agent Lumos: Unified and Modular Training for Open-Source Language Agents* (ACL 2024, 3 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large))" ;
    .

:*certainly_uncertain:_a_benchmark_and_metric_for_multimodal_epistemic_and_aleatoric_awareness*_(arxi a :Publication ;
    :title "*Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness* (ArXiv 2024, 0 citations) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric))" ;
    .

:*rewardbench:_evaluating_reward_models_for_language_modeling*_(naacl_2025,_0_citations)_([aclantholo a :Publication ;
    :title "*RewardBench: Evaluating Reward Models for Language Modeling* (NAACL 2025, 0 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the))" ;
    .

:*“tfg_flow:_training_free_guidance_in_multimodal_generative_flow”*_(icml_workshop,_2025)_–_training_ a :Publication ;
    :title "*“TFG-Flow: Training-free Guidance in Multimodal Generative Flow”* (ICML Workshop, 2025) – Training-free guidance for generative models (multimodal generation) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)) (10 citations)" ;
    .

:*“functional_interpolation_for_relative_positions_improves_long_context_transformers”*_(iclr,_2023)_ a :Publication ;
    :title "*“Functional Interpolation for Relative Positions Improves Long Context Transformers”* (ICLR, 2023) – Improved Transformer for longer context (LLM architecture) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) (language modeling)" ;
    .

:*“stable,_fast_and_accurate:_kernelized_attention_with_relative_positional_encoding”*_(neurips,_2021 a :Publication ;
    :title "*“Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding”* (NeurIPS, 2021) – Fast transformer attention techniques (LLM scaling) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Stable%2C%20Fast%20and%20Accurate%3A%20Kernelized,Attention%20with%20Relative%20Positional%20Encoding)) (35 citations)" ;
    .

:*adaptive_online_replanning_with_diffusion_models*_(neurips,_2023;_~3_citations)_([shunzh.github.io] a :Publication ;
    :title "*Adaptive Online Replanning with Diffusion Models* (NeurIPS, 2023; ~3 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Siyuan%20Zhou%2C%20Yilun%20Du%2C%20Shun,NeurIPS%29%2C%202023))" ;
    .

:*planning_with_large_language_models_for_code_generation*_(iclr,_2023;_~10_citations)_([shunzh.githu a :Publication ;
    :title "*Planning with Large Language Models for Code Generation* (ICLR, 2023; ~10 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Planning%20with%20Large%20Language%20Models,for%20Code%20Generation))" ;
    .

:*improving_reinforcement_learning_from_human_feedback_with_efficient_reward_model_ensemble*_(arxiv,_ a :Publication ;
    :title "*Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble* (arXiv, 2024; ~0 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Improving%20Reinforcement%20Learning%20from%20Human,with%20Efficient%20Reward%20Model%20Ensemble))" ;
    .

:reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)_&_large_scale_transfor a :ResearchCluster ;
    :name "Reinforcement Learning & Multi-Agent Systems (Game Ai, Hardware Optimization) & Large-Scale Transformer Language Models & Embeddings (Llm Training And Representation) & Automated Code Generation & Debugging (Llm-Driven Coding Agents)" ;
    .

:large_language_models_(llms)_and_generative_ai_systems_&_autonomous_“agentic”_ai_and_multi_step_ai_a a :ResearchCluster ;
    :name "Large Language Models (Llms) And Generative Ai Systems & Autonomous “Agentic” Ai And Multi-Step Ai Agents & Natural Language Processing (Nlp) And Ai-Driven Reasoning Pipelines" ;
    .

:large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz a :ResearchCluster ;
    :name "Large-Scale Llm Architecture And Scaling (Efficient Pretraining, Mixture-Of-Experts Models) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=I%E2%80%99M%20A%20Senior%20Research%20Scientist,And%20Multimodal%20Research%20For%20Gemini)) & Transformer Sequence Efficiency (Elastic/Dynamic Input Processing During Training And Inference) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=,Icml%29%202023)) & Multimodal Vision-And-Language Modeling (Long-Context Video-Text Understandi" ;
    .

:large_language_model_pre_training_and_architecture_&_semantic_search_and_document_reranking_with_llm a :ResearchCluster ;
    :name "Large Language Model Pre-Training And Architecture & Semantic Search And Document Reranking With Llms & Evaluation And Benchmarking Of Nlp Models" ;
    .

:multimodal_vision_language_and_audio_language_modeling_&_large_language_model_architecture_design_an a :ResearchCluster ;
    :name "Multimodal Vision-Language And Audio-Language Modeling & Large Language Model Architecture Design And Fine-Tuning & Autonomous Coding Assistants And Software Engineering Agents" ;
    .

:**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)_&_**reinforcement_learni a :ResearchCluster ;
    :name "**Llm Fine-Tuning & Adaptation** (Peft/Lora Techniques For Multi-Task Llms) & **Reinforcement Learning For Llm Reasoning** (Rlhf Pipelines To Instill Chain-Of-Thought) & **Multimodal Conversational Models** (Audio+Text Chat Ai Systems)" ;
    .

:**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au a :ResearchCluster ;
    :name "**Multimodal Language Models:** Designing And Training Large-Scale Language Models That Integrate Audio And Visual Information (E.G. Open-Source Audio–Language “Voxtral” Models) ([Khyathiraghavi.Github.Io](Https://Khyathiraghavi.Github.Io/#:~:Text=My%20Research%20Centers%20On%20Developing,Focus%20On%20Two%20Key%20Directions)). & **Llm Reasoning & Chain-Of-Thought:** Developing Reasoning Architectures And Chain-Of-Thought Techniques For Llms (E.G. “Magistral” Models For Long-Form Reasoning). & **" ;
    .

:large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_ a :ResearchCluster ;
    :name "Large Language Model Development And Tuning & Machine Learning For Ads Optimization And Recommender Systems & Model Evaluation And Benchmarking (Especially Llm Performance)" ;
    .

:openai_five_(deep_rl_game_agent) a :Project ;
    :name "OpenAI Five (Deep RL game agent)" ;
    :description "**OpenAI Five (Deep RL game agent)**: Co-developed a superhuman Dota 2 bot using distributed deep reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) (multi-agent RL, gaming)." ;
    .

:prefixrl_(circuit_design_via_rl) a :Project ;
    :name "PrefixRL (Circuit design via RL)" ;
    :description "**PrefixRL (Circuit design via RL)**: Introduced an RL approach to design parallel prefix circuits (e.g. adders, encoders) that Pareto-dominate baselines in area/delay ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)) (RL for hardware optimization)." ;
    .

:llm_generative_ai_at_xai a :Project ;
    :name "LLM/Generative AI at xAI" ;
    :description "**LLM/Generative AI at xAI**: Likely involved in building and deploying large-language-model–based applications at xAI (no specific public details available)." ;
    .

:agentic_ai_system_integration a :Project ;
    :name "Agentic AI/System Integration" ;
    :description "**Agentic AI/System Integration**: Participated in development of agentic AI systems that use LLMs to perform multi-turn reasoning or tasks (specifics unpublished)." ;
    .

:machine_learning_engineering a :Project ;
    :name "Machine Learning Engineering" ;
    :description "**Machine Learning Engineering**: Contributed Python-based ML pipelines and feature engineering for AI services at xAI (project details not publicly documented)." ;
    .

:openmoe_(icml_2024)**_–_an_open a :Project ;
    :name "OpenMoE (ICML 2024)** – An open" ;
    :description "**OpenMoE (ICML 2024)** – An open-source mixture-of-experts language model framework that explores scalable LLM architectures ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) (LLM Training & Architecture)." ;
    .

:mixeval_(neurips_2024)**_–_a_benchmark_toolkit_that_combines_multiple_llm_test_sets_into_realistic_m a :Project ;
    :name "MixEval (NeurIPS 2024)** – A benchmark toolkit that combines multiple LLM test sets into realistic mixtures for more reliable evaluation ([xuefuzhao.github.io](https" ;
    :description "**MixEval (NeurIPS 2024)** – A benchmark toolkit that combines multiple LLM test sets into realistic mixtures for more reliable evaluation ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)) (Evaluation & Benchmarking)." ;
    .

:longvila_(iclr_2025)**_–_a_long a :Project ;
    :name "LongVILA (ICLR 2025)** – A long" ;
    :description "**LongVILA (ICLR 2025)** – A long-context visual language model for video understanding, extending LLMs to model very long videos ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) (Multimodal AI & Vision-Language)." ;
    .

:cohere_rerank_(2023)**_–_led_development_of_cohere’s_rerank_system,_an_llm a :Project ;
    :name "Cohere Rerank (2023)** – Led development of Cohere’s Rerank system, an LLM" ;
    :description "**Cohere Rerank (2023)** – Led development of Cohere’s Rerank system, an LLM-powered ranking model that orders search results by relevance, significantly improving enterprise search quality ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)) (LLMs/Evaluation)." ;
    .

:rerank_3.5_upgrade_(2024)**_–_advanced_the_rerank_model_to_version_3.5_with_better_reasoning_and_mul a :Project ;
    :name "Rerank 3.5 Upgrade (2024)** – Advanced the Rerank model to version 3.5 with better reasoning and multilingual capabilities, enhancing complex query understanding and evaluation of RAG systems (LLMs/Evaluation)." ;
    :description "**Rerank 3.5 Upgrade (2024)** – Advanced the Rerank model to version 3.5 with better reasoning and multilingual capabilities, enhancing complex query understanding and evaluation of RAG systems (LLMs/Evaluation)." ;
    .

:llm_pretraining_at_cohere**_–_contributed_to_training_cohere’s_large a :Project ;
    :name "LLM Pretraining at Cohere** – Contributed to training Cohere’s large" ;
    :description "**LLM Pretraining at Cohere** – Contributed to training Cohere’s large-scale language models (e.g. the new Aya series), optimizing model architecture, data pipelines, and pretraining strategies for improved performance on reasoning and generation tasks (LLMs)." ;
    .

:devstral_(coding_agents)**_–_a_24b a :Project ;
    :name "Devstral (Coding Agents)** – A 24B" ;
    :description "**Devstral (Coding Agents)** – A 24B-parameter agentic LLM fine-tuned for software engineering tasks (developed with All Hands AI). Devstral can explore and edit large codebases using tool interfaces and long contexts; it achieved 53.6% on the SWE-Bench coding benchmark (outperforming much larger models) ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)) ([www.techtarget.com](https://www.techtarget.com/searchenterpriseai/news/366624217/Mistral-AI-intros-Dev" ;
    .

:pixtral_12b_(vision a :Project ;
    :name "Pixtral 12B (Vision" ;
    :description "**Pixtral 12B (Vision-Language LLM)** – A multimodal 12B-parameter model integrating image and text understanding. Pixtral is designed to handle vision-and-language tasks effectively in a compact model, exploring how smaller LLMs can rival larger ones on visual-text benchmarks." ;
    .

:voxtral_(audio a :Project ;
    :name "Voxtral (Audio" ;
    :description "**Voxtral (Audio-Text LLM)** – An audio-text multimodal LLM that jointly processes speech and language. Voxtral investigates unified models for hearing and reading, aiming to master audio comprehension and text generation tasks concurrently." ;
    .

:magistral_(llm_reasoning_with_rl) a :Project ;
    :name "Magistral (LLM Reasoning with RL)" ;
    :description "**Magistral (LLM Reasoning with RL):** Led development of Magistral, Mistral AI’s first reasoning-focused LLM, trained with a scalable reinforcement learning pipeline to enhance transparent chain-of-thought reasoning while preserving multimodal and instruction-following capabilities. (LLM Reasoning & RL)" ;
    .

:voxtral_(multimodal_audio_chat) a :Project ;
    :name "Voxtral (Multimodal Audio Chat)" ;
    :description "**Voxtral (Multimodal Audio Chat):** Co-authored Voxtral Mini and Small, state-of-the-art multimodal audio-chat models that process spoken audio and text, with a long-context window for up to 40min audio. Released new benchmarks for audio QA to measure speech understanding and knowledge retrieval. (Multimodal AI & Reasoning)" ;
    .

:mode_(multi a :Project ;
    :name "MoDE (Multi" ;
    :description "**MoDE (Multi-task LLM Fine-Tuning):** Proposed Mixture of Dyadic Experts, a novel multi-task parameter-efficient fine-tuning method (PEFT) for LLMs that shares projection matrices and uses rank-1 adapters with routing. Demonstrated state-of-the-art on 700+ diverse tasks (Supernatural Instructions SNI benchmark). (LLM Training & Adaptation)" ;
    .

:voxtral_&_magistral_(open a :Project ;
    :name "Voxtral & Magistral (Open" ;
    :description "**Voxtral & Magistral (Open-Source LLMs):** Developed large-scale multimodal and reasoning-focused LLMs. Voxtral is a family of audio–language models (3B–123B parameters), and Magistral is an LLM line emphasizing chain-of-thought reasoning ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions))." ;
    .

:agent_lumos_(acl_2024) a :Project ;
    :name "Agent Lumos (ACL 2024)" ;
    :description "**Agent Lumos (ACL 2024):** Introduced Lumos, a unified modular training framework for open-source language agents. Lumos learns high-level planning and grounding to tools, outperforming other open-source agents (and even GPT-4) on diverse tasks ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large))." ;
    .

:rewardbench_(naacl_2025) a :Project ;
    :name "RewardBench (NAACL 2025)" ;
    :description "**RewardBench (NAACL 2025):** Created RewardBench, a benchmark dataset and codebase for evaluating language-model reward models used in RLHF. It analyzes reward-model behavior on structured queries, exposing issues in refusals, reasoning, and alignment ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the))." ;
    .

:llm_deployment_optimization a :Project ;
    :name "LLM Deployment Optimization" ;
    :description "**LLM Deployment Optimization:** Developed techniques to improve LLM inference throughput (e.g., TensorRT-LLM optimizations) and reduce computational load, supporting NVIDIA’s NeMo/Transformer toolchains for high-demand applications ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) ([paperswithcode.com](https://paperswithcode.com/search?or" ;
    .

:automated_bidding_systems a :Project ;
    :name "Automated Bidding Systems" ;
    :description "**Automated Bidding Systems:** Applied reinforcement learning and ML methods to optimize ad bidding strategies (target area: Reinforcement Learning & Agents), leveraging large-scale data from digital advertising to maximize ROI." ;
    .

:recommender_system_modeling a :Project ;
    :name "Recommender System Modeling" ;
    :description "**Recommender System Modeling:** Designed recommendation algorithms using neural networks and LLM embeddings to improve user targeting and relevance (target area: Multimodal AI & Vision-Language)." ;
    .

:efficient_rlhf_reward_ensemble a :Project ;
    :name "Efficient RLHF Reward Ensemble" ;
    :description "**Efficient RLHF Reward Ensemble:** Developed ensemble-based reward models to improve the efficiency and alignment of reinforcement learning from human feedback ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment))." ;
    .

:adaptive_replanning_with_diffusion_models a :Project ;
    :name "Adaptive Replanning with Diffusion Models" ;
    :description "**Adaptive Replanning with Diffusion Models:** Introduced a method that uses diffusion-model-based planning to adaptively replan online, allowing agents to incorporate new observations during execution ([shunzh.github.io](https://shunzh.github.io/#:~:text=Conference%20on%20Neural%20Information%20Processing,planning))." ;
    .

:deep_learning :SPECIALIZATION_OF :machine_learning .
:reinforcement_learning :SPECIALIZATION_OF :machine_learning .
:supervised_learning :SPECIALIZATION_OF :machine_learning .
:neural_networks :SPECIALIZATION_OF :deep_learning .
:transformers :SPECIALIZATION_OF :deep_learning .
:cnns :SPECIALIZATION_OF :deep_learning .
:gpt_models :SPECIALIZATION_OF :llms .
:bert :SPECIALIZATION_OF :llms .
:training :SPECIALIZATION_OF :llms .
:fine_tuning :SPECIALIZATION_OF :llms .
:prompt_engineering :SPECIALIZATION_OF :llms .
:policy_optimization :SPECIALIZATION_OF :reinforcement_learning .
:q_learning :SPECIALIZATION_OF :reinforcement_learning .
:ppo :SPECIALIZATION_OF :reinforcement_learning .
:rlhf :SPECIALIZATION_OF :reinforcement_learning .
:vision_language :SPECIALIZATION_OF :multimodal_ai .
:audio_language :SPECIALIZATION_OF :multimodal_ai .
:cross_modal :SPECIALIZATION_OF :multimodal_ai .
:coding_agents :SPECIALIZATION_OF :code_generation .
:program_synthesis :SPECIALIZATION_OF :code_generation .
:code_completion :SPECIALIZATION_OF :code_generation .
:benchmarking :SPECIALIZATION_OF :evaluation .
:metrics :SPECIALIZATION_OF :evaluation .
:testing :SPECIALIZATION_OF :evaluation .
:jonathan_raiman :WORKS_AT :nvidia .
:jonathan_raiman :HAS_ROLE :ai_research:_co_creator_openai_five,_prefixrl,_deepspeech_2,_deepvoice_1,2,3,_deeptype_1,2,_chipnemo .
:jonathan_raiman :HAS_SKILL :reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization) .
:jonathan_raiman :HAS_SKILL :large_scale_transformer_language_models_&_embeddings_(llm_training_and_representation) .
:jonathan_raiman :HAS_SKILL :automated_code_generation_&_debugging_(llm_driven_coding_agents) .
:jonathan_raiman :HAS_SKILL :ai_model_evaluation_&_benchmarking_(performance_optimization_and_comparisons) .
:jonathan_raiman :BELONGS_TO_CLUSTER :reinforcement_learning_&_multi_agent_systems_(game_ai,_hardware_optimization)_&_large_scale_transfor .
:jonathan_raiman :CONTRIBUTED_TO :openai_five_(deep_rl_game_agent) .
:jonathan_raiman :CONTRIBUTED_TO :prefixrl_(circuit_design_via_rl) .
:jonathan_raiman :AUTHORED :effective_large_language_model_debugging_with_best_first_tree_search_(arxiv,_2024,_0_citations) .
:jonathan_raiman :AUTHORED :prefixrl:_optimization_of_parallel_prefix_circuits_using_deep_reinforcement_learning_(dac_2021,_5_ci .
:jonathan_raiman :AUTHORED :nv_embed:_improved_techniques_for_training_llms_as_generalist_embedding_models_(arxiv,_2024,_0_citat .
:deepa_nalla :WORKS_AT :xai .
:deepa_nalla :HAS_ROLE :ai_engineer_|_masters_graduate___business_analytics_and_ai__|_ex_deloitte_|_python_|_machine_learnin .
:deepa_nalla :HAS_SKILL :large_language_models_(llms)_and_generative_ai_systems .
:deepa_nalla :HAS_SKILL :autonomous_“agentic”_ai_and_multi_step_ai_agents .
:deepa_nalla :HAS_SKILL :natural_language_processing_(nlp)_and_ai_driven_reasoning_pipelines .
:deepa_nalla :HAS_SKILL :machine_learning_model_development_and_api_deployment_for_ai .
:deepa_nalla :BELONGS_TO_CLUSTER :large_language_models_(llms)_and_generative_ai_systems_&_autonomous_“agentic”_ai_and_multi_step_ai_a .
:deepa_nalla :CONTRIBUTED_TO :llm_generative_ai_at_xai .
:deepa_nalla :CONTRIBUTED_TO :agentic_ai_system_integration .
:deepa_nalla :CONTRIBUTED_TO :machine_learning_engineering .
:deepa_nalla :AUTHORED :*no_known_publications_were_found_by_deepa_nalla_in_the_areas_of_llms,_multimodal_ai,_reinforcement_ .
:fuzhao_xue :WORKS_AT :google_deepmind .
:fuzhao_xue :HAS_ROLE :large_language_model_researcher_|_homepage_(xuefuzhao.github.io) .
:fuzhao_xue :HAS_SKILL :large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz .
:fuzhao_xue :HAS_SKILL :transformer_sequence_efficiency_(elastic_dynamic_input_processing_during_training_and_inference)_([x .
:fuzhao_xue :HAS_SKILL :multimodal_vision_and_language_modeling_(long_context_video_text_understanding,_unified_visual_token .
:fuzhao_xue :HAS_SKILL :llm_evaluation_and_benchmarking_(real_world_mixture_based_benchmark_design)_([xuefuzhao.github.io](h .
:fuzhao_xue :BELONGS_TO_CLUSTER :large_scale_llm_architecture_and_scaling_(efficient_pretraining,_mixture_of_experts_models)_([xuefuz .
:fuzhao_xue :CONTRIBUTED_TO :openmoe_(icml_2024)**_–_an_open .
:fuzhao_xue :CONTRIBUTED_TO :mixeval_(neurips_2024)**_–_a_benchmark_toolkit_that_combines_multiple_llm_test_sets_into_realistic_m .
:fuzhao_xue :CONTRIBUTED_TO :longvila_(iclr_2025)**_–_a_long .
:fuzhao_xue :AUTHORED :*openmoe:_an_early_effort_on_open_mixture_of_experts_language_models*_(icml_2024,_0_citations) .
:fuzhao_xue :AUTHORED :*mixeval:_deriving_wisdom_of_the_crowd_from_llm_benchmark_mixtures*_(neurips_2024,_0_citations) .
:fuzhao_xue :AUTHORED :*longvila:_scaling_long_context_visual_language_models_for_long_videos*_(iclr_2025,_0_citations) .
:sylvie_shi :WORKS_AT :cohere .
:sylvie_shi :HAS_ROLE :llm_pre_training_at_cohere .
:sylvie_shi :HAS_SKILL :large_language_model_pre_training_and_architecture .
:sylvie_shi :HAS_SKILL :semantic_search_and_document_reranking_with_llms .
:sylvie_shi :HAS_SKILL :evaluation_and_benchmarking_of_nlp_models .
:sylvie_shi :HAS_SKILL :retrieval_augmented_generation_and_rag_systems .
:sylvie_shi :BELONGS_TO_CLUSTER :large_language_model_pre_training_and_architecture_&_semantic_search_and_document_reranking_with_llm .
:sylvie_shi :CONTRIBUTED_TO :cohere_rerank_(2023)**_–_led_development_of_cohere’s_rerank_system,_an_llm .
:sylvie_shi :CONTRIBUTED_TO :rerank_3.5_upgrade_(2024)**_–_advanced_the_rerank_model_to_version_3.5_with_better_reasoning_and_mul .
:sylvie_shi :CONTRIBUTED_TO :llm_pretraining_at_cohere**_–_contributed_to_training_cohere’s_large .
:sylvie_shi :AUTHORED :*“cohere_rerank:_enhancing_semantic_search_with_llms”*_(cohere_blog,_2023,_0_citations) .
:sylvie_shi :AUTHORED :*“introducing_rerank_3.5:_precise_ai_search”*_(cohere_blog,_2024,_0_citations) .
:sylvie_shi :AUTHORED :*“aya_23_8b:_a_multilingual_large_language_model_technical_report”*_(cohere_technical_report,_2023,_ .
:sagar_vaze :WORKS_AT :mistral_ai .
:sagar_vaze :HAS_ROLE :multimodal_llms_@_mistral_ai .
:sagar_vaze :HAS_SKILL :multimodal_vision_language_and_audio_language_modeling .
:sagar_vaze :HAS_SKILL :large_language_model_architecture_design_and_fine_tuning .
:sagar_vaze :HAS_SKILL :autonomous_coding_assistants_and_software_engineering_agents .
:sagar_vaze :HAS_SKILL :model_evaluation_and_robustness_(open_set_ood_detection) .
:sagar_vaze :BELONGS_TO_CLUSTER :multimodal_vision_language_and_audio_language_modeling_&_large_language_model_architecture_design_an .
:sagar_vaze :CONTRIBUTED_TO :devstral_(coding_agents)**_–_a_24b .
:sagar_vaze :CONTRIBUTED_TO :pixtral_12b_(vision .
:sagar_vaze :CONTRIBUTED_TO :voxtral_(audio .
:sagar_vaze :AUTHORED :*devstral:_fine_tuning_language_models_for_coding_agent_applications*_(arxiv,_2025,_0_citations) .
:sagar_vaze :AUTHORED :*pixtral_12b:_can_a_smaller_model_punch_above_its_weight_in_vision_and_language_tasks?*_(arxiv,_2024 .
:sagar_vaze :AUTHORED :*magistral:_can_mistral_out_reason_everyone_else_by_building_its_own_ai_learning_system?*_(arxiv,_20 .
:abhinav_rastogi :WORKS_AT :mistral_ai .
:abhinav_rastogi :HAS_ROLE :research_scientist_at_mistral_ai_|_llm_reasoning .
:abhinav_rastogi :HAS_SKILL :**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms) .
:abhinav_rastogi :HAS_SKILL :**reinforcement_learning_for_llm_reasoning**_(rlhf_pipelines_to_instill_chain_of_thought) .
:abhinav_rastogi :HAS_SKILL :**multimodal_conversational_models**_(audio+text_chat_ai_systems) .
:abhinav_rastogi :HAS_SKILL :**task_oriented_dialogue_systems**_(end_to_end_dialogue_agents_and_evaluation) .
:abhinav_rastogi :BELONGS_TO_CLUSTER :**llm_fine_tuning_&_adaptation**_(peft_lora_techniques_for_multi_task_llms)_&_**reinforcement_learni .
:abhinav_rastogi :CONTRIBUTED_TO :magistral_(llm_reasoning_with_rl) .
:abhinav_rastogi :CONTRIBUTED_TO :voxtral_(multimodal_audio_chat) .
:abhinav_rastogi :CONTRIBUTED_TO :mode_(multi .
:abhinav_rastogi :AUTHORED :**mode:_effective_multi_task_parameter_efficient_fine_tuning_with_a_mixture_of_dyadic_experts**_(fin .
:abhinav_rastogi :AUTHORED :**voxtral_mini_small:_multimodal_audio_chat_models**_(arxiv_2025,_0_citations) .
:abhinav_rastogi :AUTHORED :**magistral:_mistral’s_first_reasoning_focused_llm**_(mistral_ai_research,_2025,_not_peer_reviewed) .
:khyathi_chandu :WORKS_AT :mistral_ai .
:khyathi_chandu :HAS_ROLE :ph.d,_multimodal_llms_@_mistral_ai_|_prev_@ai2,_meta,_google,_apple_|_ph.d._@cmu_|_rising_stars_@ucb .
:khyathi_chandu :HAS_SKILL :**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au .
:khyathi_chandu :HAS_SKILL :**llm_reasoning_&_chain_of_thought:**_developing_reasoning_architectures_and_chain_of_thought_techni .
:khyathi_chandu :HAS_SKILL :**language_agent_architectures:**_building_and_training_open_source_llm_based_agents_with_modular_pl .
:khyathi_chandu :HAS_SKILL :**evaluation_&_uncertainty_metrics:**_creating_benchmarks_and_metrics_to_evaluate_model_behavior,_su .
:khyathi_chandu :BELONGS_TO_CLUSTER :**multimodal_language_models:**_designing_and_training_large_scale_language_models_that_integrate_au .
:khyathi_chandu :CONTRIBUTED_TO :voxtral_&_magistral_(open .
:khyathi_chandu :CONTRIBUTED_TO :agent_lumos_(acl_2024) .
:khyathi_chandu :CONTRIBUTED_TO :rewardbench_(naacl_2025) .
:khyathi_chandu :AUTHORED :*agent_lumos:_unified_and_modular_training_for_open_source_language_agents*_(acl_2024,_3_citations)_ .
:khyathi_chandu :AUTHORED :*certainly_uncertain:_a_benchmark_and_metric_for_multimodal_epistemic_and_aleatoric_awareness*_(arxi .
:khyathi_chandu :AUTHORED :*rewardbench:_evaluating_reward_models_for_language_modeling*_(naacl_2025,_0_citations)_([aclantholo .
:shangda_li :WORKS_AT :nvidia .
:shangda_li :HAS_ROLE :large_language_model,_machine_learning,_ads_automated_bidding,_recommender_system. .
:shangda_li :HAS_SKILL :large_language_model_development_and_tuning .
:shangda_li :HAS_SKILL :machine_learning_for_ads_optimization_and_recommender_systems .
:shangda_li :HAS_SKILL :model_evaluation_and_benchmarking_(especially_llm_performance) .
:shangda_li :HAS_SKILL :practical_deployment_of_ml_rl_techniques_in_industry_settings .
:shangda_li :BELONGS_TO_CLUSTER :large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_ .
:shangda_li :CONTRIBUTED_TO :llm_deployment_optimization .
:shangda_li :CONTRIBUTED_TO :automated_bidding_systems .
:shangda_li :CONTRIBUTED_TO :recommender_system_modeling .
:shangda_li :AUTHORED :*“tfg_flow:_training_free_guidance_in_multimodal_generative_flow”*_(icml_workshop,_2025)_–_training_ .
:shangda_li :AUTHORED :*“functional_interpolation_for_relative_positions_improves_long_context_transformers”*_(iclr,_2023)_ .
:shangda_li :AUTHORED :*“stable,_fast_and_accurate:_kernelized_attention_with_relative_positional_encoding”*_(neurips,_2021 .
:shun_zhang :WORKS_AT :nvidia .
:shun_zhang :HAS_ROLE :embodied_ai_+_reasoning_@_nvidia .
:shun_zhang :HAS_SKILL :reinforcement_learning_(policy_optimization,_safe_adaptive_rl) .
:shun_zhang :HAS_SKILL :large_language_models_(llm_based_planning_and_code_generation) .
:shun_zhang :HAS_SKILL :generative_models_for_sequential_decision_making_(diffusion_planning,_transformer_reasoning) .
:shun_zhang :HAS_SKILL :reward_modeling_and_value_alignment_(rl_from_human_feedback,_ensemble_reward_models) .
:shun_zhang :BELONGS_TO_CLUSTER :large_language_model_development_and_tuning_&_machine_learning_for_ads_optimization_and_recommender_ .
:shun_zhang :CONTRIBUTED_TO :efficient_rlhf_reward_ensemble .
:shun_zhang :CONTRIBUTED_TO :adaptive_replanning_with_diffusion_models .
:shun_zhang :AUTHORED :*adaptive_online_replanning_with_diffusion_models*_(neurips,_2023;_~3_citations)_([shunzh.github.io] .
:shun_zhang :AUTHORED :*planning_with_large_language_models_for_code_generation*_(iclr,_2023;_~10_citations)_([shunzh.githu .
:shun_zhang :AUTHORED :*improving_reinforcement_learning_from_human_feedback_with_efficient_reward_model_ensemble*_(arxiv,_ .
:shangda_li :SIMILAR_TO :shun_zhang .
