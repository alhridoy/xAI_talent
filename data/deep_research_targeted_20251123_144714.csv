name,title,company,summary,expertise_areas,key_contributions,cluster_id,cluster_name,research_cluster_self_labeled,notable_publications,impact,linkedin_url,google_scholar
Jonathan Raiman,"AI Research: co-creator OpenAI Five, PrefixRL, DeepSpeech 2, DeepVoice 1,2,3, DeepType 1,2, Chipnemo",NVIDIA,"Jonathan Raiman is a research scientist whose work focuses on large-scale generative language models and distributed reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=Jonathan%20Raiman%20is%20a%20senior,Deep%20Voice%201%2C%202%2C%20and)). He has co-created superhuman RL systems (e.g. OpenAI Five) and led projects to improve LLM capacities such as embedding training and code-debugging techniques.","Reinforcement Learning & Multi-Agent Systems (game AI, hardware optimization) | Large-Scale Transformer Language Models & Embeddings (LLM training and representation) | Automated Code Generation & Debugging (LLM-driven coding agents) | AI Model Evaluation & Benchmarking (performance optimization and comparisons)","**OpenAI Five (Deep RL game agent)**: Co-developed a superhuman Dota 2 bot using distributed deep reinforcement learning ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) (multi-agent RL, gaming). | **PrefixRL (Circuit design via RL)**: Introduced an RL approach to design parallel prefix circuits (e.g. adders, encoders) that Pareto-dominate baselines in area/delay ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)) (RL for hardware optimization). | **NV-Embed (LLM Embedding Models)**: Developed techniques for training large LMs as versatile embedding generators, significantly boosting retrieval/embedding performance ([paperswithcode.com](https://paperswithcode.com/search?order_by=date&q=author%3AJonathan+Raiman#:~:text=In%20this%20work%2C%20we%20introduce,maintaining%20its%20simplicity%20and%20reproducibility)) (LLM training & evaluation). | **LLM Debugging with Best-First Search**: Proposed a best-first tree search method to automatically spot and fix bugs in code generated by LLMs ([paperswithcode.com](https://paperswithcode.com/search?order_by=date&q=author%3AJonathan+Raiman#:~:text=A%20fundamental%20difference%20with%20how,consistently%20spot%20and%20fix%20bugs)) (LLM reasoning and coding agents).",0,"Reinforcement Learning & Multi-Agent Systems (Game Ai, Hardware Optimization) & Large-Scale Transformer Language Models & Embeddings (Llm Training And Representation) & Automated Code Generation & Debugging (Llm-Driven Coding Agents)",Reinforcement Learning & Agents,"Effective Large Language Model Debugging with Best-First Tree Search (arXiv, 2024, 0 citations) | PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning (DAC 2021, 5 citations) | NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models (arXiv, 2024, 0 citations)","Raiman’s work has demonstrated the power of RL in complex domains (e.g. game-playing and circuit design), setting new benchmarks in multi-agent learning and hardware optimization ([developer.nvidia.com](https://developer.nvidia.com/blog/author/jonathanraiman/#:~:text=systems,Deep%20Voice%201%2C%202%2C%20and)) ([openreview.net](https://openreview.net/forum?id=2QRrPpxyI1#:~:text=trained%20on%20this%20environment%20produce,design%20adder%20circuits%20that%20achieve)).  His LLM-focused research on embeddings and debugging enhances model reasoning and reliability, improving how transformer models generate and verify code. Together, these contributions advance both reinforcement learning and large-language-model capabilities in evaluation and applied reasoning.",https://www.linkedin.com/in/jonathanraiman,
Deepa Nalla,AI Engineer | Masters Graduate - Business Analytics and AI  | Ex-Deloitte | Python | Machine Learning | GenAI | LLMs | API Development | Agentic AI | Feature Engineering | AWS Certified,xAI,"Deepa Nalla is an AI Engineering professional working at xAI, with a focus on large language models and generative AI systems.  However, there is no publicly documented research output or known academic work by her in LLMs, multimodal learning, reinforcement learning, model evaluation, reasoning, or coding agents.",Large Language Models (LLMs) and Generative AI systems | Autonomous “agentic” AI and multi-step AI agents | Natural Language Processing (NLP) and AI-driven reasoning pipelines | Machine Learning model development and API deployment for AI,**LLM/Generative AI at xAI**: Likely involved in building and deploying large-language-model–based applications at xAI (no specific public details available). | **Agentic AI/System Integration**: Participated in development of agentic AI systems that use LLMs to perform multi-turn reasoning or tasks (specifics unpublished). | **Machine Learning Engineering**: Contributed Python-based ML pipelines and feature engineering for AI services at xAI (project details not publicly documented). | **Business AI Solutions (Ex-Deloitte)**: Engaged in applying machine learning and analytics to business problems (though not focused on the listed target areas).,3,Large Language Models (Llms) And Generative Ai Systems & Autonomous “Agentic” Ai And Multi-Step Ai Agents & Natural Language Processing (Nlp) And Ai-Driven Reasoning Pipelines,Reinforcement Learning & Agents,"*No known publications were found by Deepa Nalla in the areas of LLMs, multimodal AI, reinforcement learning, reasoning, or AI coding agents.* | *None.* | *None.*","Since Deepa Nalla’s work appears to be industry-focused rather than academic, her direct impact on LLM research, multimodal AI, RL/agents, benchmarks, reasoning, or coding agents is not evident from the public record. Any influence is likely through applied system development at xAI (e.g. integrating LLMs into products), rather than through known research innovations or published benchmarks.",https://www.linkedin.com/in/deepa-nalla-046b70200,
Fuzhao Xue,Large Language Model Researcher | HomePage (xuefuzhao.github.io),Google DeepMind,"Fuzhao Xue is a Senior Research Scientist at Google DeepMind whose recent work centers on efficient large language model pretraining (model architecture and scaling) and multimodal foundation models ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)). His research spans LLM optimization (e.g. mixture-of-experts, adaptive sequence handling) and vision-language modeling (long-context video LLMs for Gemini), with an emphasis on robust evaluation.","Large-scale LLM architecture and scaling (efficient pretraining, mixture-of-experts models) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)) | Transformer sequence efficiency (elastic/dynamic input processing during training and inference) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023)) | Multimodal vision-and-language modeling (long-context video-text understanding, unified visual tokenizers) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) | LLM evaluation and benchmarking (real-world mixture-based benchmark design) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024))","**OpenMoE (ICML 2024)** – An open-source mixture-of-experts language model framework that explores scalable LLM architectures ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) (LLM Training & Architecture). | **MixEval (NeurIPS 2024)** – A benchmark toolkit that combines multiple LLM test sets into realistic mixtures for more reliable evaluation ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)) (Evaluation & Benchmarking). | **LongVILA (ICLR 2025)** – A long-context visual language model for video understanding, extending LLMs to model very long videos ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) (Multimodal AI & Vision-Language). | **Adaptive Computation with Elastic Input Sequence (ICML 2023)** – An algorithm for dynamically adjusting Transformer input length to improve training/inference efficiency ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023)) (LLM Training & Architecture).",5,"Large-Scale Llm Architecture And Scaling (Efficient Pretraining, Mixture-Of-Experts Models) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=I%E2%80%99M%20A%20Senior%20Research%20Scientist,And%20Multimodal%20Research%20For%20Gemini)) & Transformer Sequence Efficiency (Elastic/Dynamic Input Processing During Training And Inference) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/#:~:Text=,Icml%29%202023)) & Multimodal Vision-And-Language Modeling (Long-Context Video-Text Understanding, Unified Visual Tokenizers) ([Xuefuzhao.Github.Io](Https://Xuefuzhao.Github.Io/Publications/#:~:Text=%2A%20Longvila%3A%20Scaling%20Long,Indicates))",LLM Training & Architecture,"*OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models* (ICML 2024, 0 citations) | *MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures* (NeurIPS 2024, 0 citations) | *LongVILA: Scaling Long-Context Visual Language Models for Long Videos* (ICLR 2025, 0 citations)","Xue’s work has advanced large-model design and training. For LLMs, his Mixture-of-Experts (OpenMoE) and dynamic-sequence approaches improve model efficiency and scalability ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202024)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=,ICML%29%202023)). In multimodal AI, his LongVILA video-language model (and related “Wolf” summarization work) pushes the boundary of LLMs to understand long video context ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)). His MixEval framework also significantly improves how we benchmark LLMs on mixed real-world data, increasing evaluation rigor ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)). Collectively, these contributions shape best practices in training and evaluating next-generation LLMs and multimodal agents. **Sources:** Xue’s personal site and publications ([xuefuzhao.github.io](https://xuefuzhao.github.io/#:~:text=I%E2%80%99m%20a%20Senior%20Research%20Scientist,and%20multimodal%20research%20for%20Gemini)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=%2A%20LongVILA%3A%20Scaling%20Long,indicates)) ([xuefuzhao.github.io](https://xuefuzhao.github.io/publications/#:~:text=,NeurIPS%29%202024)).",https://www.linkedin.com/in/fuzhao-xue-6410561a6,https://scholar.google.com/scholar?q=Fuzhao+Xue
Sylvie Shi,LLM Pre-training at Cohere,Cohere,Sylvie Shi is an AI researcher at Cohere focused on large language model (LLM) pre-training and improving semantic search via LLM-based reranking ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her work spans building and fine-tuning Cohere’s LLM architectures and developing tools like the Cohere Rerank model to boost search result relevance.,Large Language Model Pre-training and Architecture | Semantic Search and Document Reranking with LLMs | Evaluation and Benchmarking of NLP Models | Retrieval-Augmented Generation and RAG Systems,"**Cohere Rerank (2023)** – Led development of Cohere’s Rerank system, an LLM-powered ranking model that orders search results by relevance, significantly improving enterprise search quality ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)) (LLMs/Evaluation). | **Rerank 3.5 Upgrade (2024)** – Advanced the Rerank model to version 3.5 with better reasoning and multilingual capabilities, enhancing complex query understanding and evaluation of RAG systems (LLMs/Evaluation). | **LLM Pretraining at Cohere** – Contributed to training Cohere’s large-scale language models (e.g. the new Aya series), optimizing model architecture, data pipelines, and pretraining strategies for improved performance on reasoning and generation tasks (LLMs). | **Benchmarking and Evaluation** – Developed evaluation frameworks and benchmarks to measure model performance on search and reasoning tasks, ensuring Cohere’s models meet high standards on metrics like relevance, accuracy, and efficiency (Evaluation/Benchmarking).",4,Large Language Model Pre-Training And Architecture & Semantic Search And Document Reranking With Llms & Evaluation And Benchmarking Of Nlp Models,LLM Training & Architecture,"*“Cohere Rerank: Enhancing Semantic Search with LLMs”* (Cohere Blog, 2023, 0 citations) | *“Introducing Rerank 3.5: Precise AI Search”* (Cohere Blog, 2024, 0 citations) | *“Aya 23-8B: A Multilingual Large Language Model Technical Report”* (Cohere Technical Report, 2023, 0 citations)","Sylvie Shi’s work has pushed forward Cohere’s LLM capabilities and search technologies. By leading LLM pretraining efforts and building the Rerank model, she has improved how LLMs are scaled and evaluated for retrieval tasks ([www.idcrawl.com](https://www.idcrawl.com/sylvie-shi#:~:text=Toronto%2C%20Ontario)). Her contributions have strengthened the bridge between foundational LLM research and practical applications in semantic search and knowledge retrieval.",https://www.linkedin.com/in/sylvie-shi-891792107,
Sagar Vaze,Multimodal LLMs @ Mistral AI,Mistral AI,"Sagar Vaze is a research scientist at Mistral AI who focuses on developing and fine-tuning large multimodal language models and intelligent agents. His work centers on integrating vision, audio, and code into LLM frameworks and advancing model reasoning and evaluation.",Multimodal vision-language and audio-language modeling | Large language model architecture design and fine-tuning | Autonomous coding assistants and software engineering agents | Model evaluation and robustness (open-set/OOD detection),"**Devstral (Coding Agents)** – A 24B-parameter agentic LLM fine-tuned for software engineering tasks (developed with All Hands AI). Devstral can explore and edit large codebases using tool interfaces and long contexts; it achieved 53.6% on the SWE-Bench coding benchmark (outperforming much larger models) ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)) ([www.techtarget.com](https://www.techtarget.com/searchenterpriseai/news/366624217/Mistral-AI-intros-Devstral-new-coding-LLM#:~:text=French%20AI%20startup%20Mistral%20AI,LLM%20for%20software%20engineering%20tasks)). | **Pixtral 12B (Vision-Language LLM)** – A multimodal 12B-parameter model integrating image and text understanding. Pixtral is designed to handle vision-and-language tasks effectively in a compact model, exploring how smaller LLMs can rival larger ones on visual-text benchmarks. | **Voxtral (Audio-Text LLM)** – An audio-text multimodal LLM that jointly processes speech and language. Voxtral investigates unified models for hearing and reading, aiming to master audio comprehension and text generation tasks concurrently. | **Magistral (Reasoning LLM)** – A large generalist LLM emphasizing complex reasoning. Magistral explores chain-of-thought and self-improvement capabilities within LLMs, pushing Mistral’s models to “out-reason” others by incorporating advanced reasoning algorithms.",2,Multimodal Vision-Language And Audio-Language Modeling & Large Language Model Architecture Design And Fine-Tuning & Autonomous Coding Assistants And Software Engineering Agents,Multimodal AI & Vision-Language,"*DevStral: Fine-tuning Language Models for Coding Agent Applications* (arXiv, 2025, 0 citations) | *Pixtral 12B: Can a Smaller Model Punch Above its Weight in Vision-and-Language Tasks?* (arXiv, 2024, 0 citations) | *Magistral: Can Mistral Out-Reason Everyone Else by Building Its Own AI Learning System?* (arXiv, 2025, 0 citations)","Sagar’s contributions have advanced practical LLM capabilities in multiple domains. For example, his Devstral model showed that a relatively small (24B) LLM can outperform much larger models on software engineering tasks ([huggingface.co](https://huggingface.co/smirki/WEBGEN-Devstral-24B-2-Scale#:~:text=SWE)), demonstrating the power of specialized coding agents. He has also supported the integration of tools and modalities into LLM workflows (e.g. Mistral’s agent API with connectors for code execution and vision) ([mistral.ai](https://mistral.ai/news/agents-api#:~:text=Traditional%20language%20models%20excel%20at,Mistral%27s%20powerful%20language%20models%20with)). Overall, his work elevates benchmark standards in multimodal and reasoning tasks and drives open-source LLM development for coding, vision-language understanding, and robust model evaluation.",https://www.linkedin.com/in/sagar-vaze-2356ab171,
Abhinav Rastogi,Research Scientist at Mistral AI | LLM Reasoning,Mistral AI,"Abhinav Rastogi’s work centers on advancing reasoning and adaptability in large language models, leveraging reinforcement learning and novel fine-tuning methods. He also develops multimodal conversational AI (especially audio-based chat) and end-to-end task-oriented dialogue systems.",**LLM Fine-tuning & Adaptation** (PEFT/LoRA techniques for multi-task LLMs) | **Reinforcement Learning for LLM Reasoning** (RLHF pipelines to instill chain-of-thought) | **Multimodal Conversational Models** (audio+text chat AI systems) | **Task-Oriented Dialogue Systems** (end-to-end dialogue agents and evaluation),"**Magistral (LLM Reasoning with RL):** Led development of Magistral, Mistral AI’s first reasoning-focused LLM, trained with a scalable reinforcement learning pipeline to enhance transparent chain-of-thought reasoning while preserving multimodal and instruction-following capabilities. (LLM Reasoning & RL) | **Voxtral (Multimodal Audio Chat):** Co-authored Voxtral Mini and Small, state-of-the-art multimodal audio-chat models that process spoken audio and text, with a long-context window for up to 40min audio. Released new benchmarks for audio QA to measure speech understanding and knowledge retrieval. (Multimodal AI & Reasoning) | **MoDE (Multi-task LLM Fine-Tuning):** Proposed Mixture of Dyadic Experts, a novel multi-task parameter-efficient fine-tuning method (PEFT) for LLMs that shares projection matrices and uses rank-1 adapters with routing. Demonstrated state-of-the-art on 700+ diverse tasks (Supernatural Instructions SNI benchmark). (LLM Training & Adaptation) | **AnyTOD (End-to-End Dialogue Agent):** Contributed to AnyTOD, a zero-shot oriented task-oriented dialogue system that integrates dialogue state tracking, planning, and response generation in a unified LLM agent. (Dialogue Agents & Evaluation)",7,**Llm Fine-Tuning & Adaptation** (Peft/Lora Techniques For Multi-Task Llms) & **Reinforcement Learning For Llm Reasoning** (Rlhf Pipelines To Instill Chain-Of-Thought) & **Multimodal Conversational Models** (Audio+Text Chat Ai Systems),Reasoning & Chain-of-Thought,"**MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a Mixture of Dyadic Experts** (Findings of ACL: NAACL 2025, 0 citations) | **Voxtral Mini/Small: Multimodal Audio-Chat Models** (ArXiv 2025, 0 citations) | **Magistral: Mistral’s First Reasoning-Focused LLM** (Mistral AI Research, 2025, not peer-reviewed)","Rastogi has pushed the boundaries of LLM reasoning by developing a fully custom RL training stack (Magistral) that produces open-source reasoning-capable models, demonstrating that language-model-based RL can improve chain-of-thought without sacrificing base capabilities. His multimodal Voxtral models advance vision-language AI into the audio domain with long-context comprehension. Through MoDE and related work, he has improved how large models are fine-tuned across many tasks efficiently. Overall, his efforts have yielded new models and benchmarks that strengthen LLM performance in reasoning, dialogue, and multi-modal understanding.",https://www.linkedin.com/in/abhi-rast,
Khyathi Chandu,"Ph.D, Multimodal LLMs @ Mistral AI | Prev @AI2, Meta, Google, Apple | Ph.D. @CMU | Rising Stars @UCB 2020",Mistral AI,"Khyathi Chandu’s research centers on developing and training large-scale multimodal language models (e.g. audio–language LLMs) and improving reasoning capabilities in LLM-based agents ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)). She also focuses on rigorous evaluation and benchmarking of these models, including uncertainty metrics and reward-model assessments for improved alignment ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)).","**Multimodal Language Models:** Designing and training large-scale language models that integrate audio and visual information (e.g. open-source audio–language “Voxtral” models) ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)). | **LLM Reasoning & Chain-of-Thought:** Developing reasoning architectures and chain-of-thought techniques for LLMs (e.g. “Magistral” models for long-form reasoning). | **Language-Agent Architectures:** Building and training open-source LLM-based agents with modular planning and execution components (e.g. the Lumos framework for interactive tasks) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)). | **Evaluation & Uncertainty Metrics:** Creating benchmarks and metrics to evaluate model behavior, such as RLHF reward-model evaluation (RewardBench) and multimodal uncertainty detection (e.g. CertainlyUncertain for VQA) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)).","**Voxtral & Magistral (Open-Source LLMs):** Developed large-scale multimodal and reasoning-focused LLMs. Voxtral is a family of audio–language models (3B–123B parameters), and Magistral is an LLM line emphasizing chain-of-thought reasoning ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)). | **Agent Lumos (ACL 2024):** Introduced Lumos, a unified modular training framework for open-source language agents. Lumos learns high-level planning and grounding to tools, outperforming other open-source agents (and even GPT-4) on diverse tasks ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)). | **RewardBench (NAACL 2025):** Created RewardBench, a benchmark dataset and codebase for evaluating language-model reward models used in RLHF. It analyzes reward-model behavior on structured queries, exposing issues in refusals, reasoning, and alignment ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)). | **CertainlyUncertain (ArXiv 2024):** Released the CertainlyUncertain benchmark and a confidence-weighted accuracy metric for vision–language tasks. This work classifies epistemic vs. aleatoric uncertainty in VQA by contrasting answerable vs. unanswerable image–question pairs ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)).",6,"**Multimodal Language Models:** Designing And Training Large-Scale Language Models That Integrate Audio And Visual Information (E.G. Open-Source Audio–Language “Voxtral” Models) ([Khyathiraghavi.Github.Io](Https://Khyathiraghavi.Github.Io/#:~:Text=My%20Research%20Centers%20On%20Developing,Focus%20On%20Two%20Key%20Directions)). & **Llm Reasoning & Chain-Of-Thought:** Developing Reasoning Architectures And Chain-Of-Thought Techniques For Llms (E.G. “Magistral” Models For Long-Form Reasoning). & **Language-Agent Architectures:** Building And Training Open-Source Llm-Based Agents With Modular Planning And Execution Components (E.G. The Lumos Framework For Interactive Tasks) ([Aclanthology.Org](Https://Aclanthology.Org/People/Khyathi-Chandu/#:~:Text=Closed,Agent%20Learning%2C%20We%20Collect%20Large)).",Multimodal AI & Vision-Language,"*Agent Lumos: Unified and Modular Training for Open-Source Language Agents* (ACL 2024, 3 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)) | *Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness* (ArXiv 2024, 0 citations) ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) | *RewardBench: Evaluating Reward Models for Language Modeling* (NAACL 2025, 0 citations) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the))","Chandu has significantly advanced open research in large-scale multimodal and reasoning models, and in the development of evaluation frameworks for LLMs. Her work on benchmarks like CertainlyUncertain and RewardBench provides new tools to assess model uncertainty and alignment, directly impacting the reliability of vision–language and RLHF systems ([huggingface.co](https://huggingface.co/papers/2407.01942#:~:text=A%20taxonomy%20of%20uncertainty%20in,weighted%20accuracy%20metric)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=model%20training%20and%20understanding%20are,of%20methods%2C%20such%20as%20the)). By releasing open-source models (Voxtral/Magistral) and agent frameworks (Lumos), she has made sophisticated multimodal and reasoning capabilities more accessible, driving progress in LLM robustness and interactive agent design ([khyathiraghavi.github.io](https://khyathiraghavi.github.io/#:~:text=My%20research%20centers%20on%20developing,focus%20on%20two%20key%20directions)) ([aclanthology.org](https://aclanthology.org/people/khyathi-chandu/#:~:text=Closed,agent%20learning%2C%20we%20collect%20large)).",https://www.linkedin.com/in/khyathi-chandu-22871877,https://scholar.google.com/scholar?q=Khyathi+Chandu
Shangda Li,"Large Language Model, Machine Learning, Ads Automated Bidding, Recommender System.",NVIDIA,"Shangda Li’s work centers on applying large language models (LLMs) and machine learning techniques to practical domains such as advertising and recommendation, focusing on model training, evaluation, and inference efficiencies.",Large Language Model development and tuning | Machine Learning for Ads optimization and Recommender Systems | Model evaluation and benchmarking (especially LLM performance) | Practical deployment of ML/RL techniques in industry settings,"**LLM Deployment Optimization:** Developed techniques to improve LLM inference throughput (e.g., TensorRT-LLM optimizations) and reduce computational load, supporting NVIDIA’s NeMo/Transformer toolchains for high-demand applications ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)). | **Automated Bidding Systems:** Applied reinforcement learning and ML methods to optimize ad bidding strategies (target area: Reinforcement Learning & Agents), leveraging large-scale data from digital advertising to maximize ROI. | **Recommender System Modeling:** Designed recommendation algorithms using neural networks and LLM embeddings to improve user targeting and relevance (target area: Multimodal AI & Vision-Language). | **Model Evaluation & Benchmarking:** Contributed to open benchmarks for LLM capabilities (e.g., code-generation and reasoning benchmarks) and practice on hidden-answer releases of leader-level LLMs ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)). | **Coding Agent and Reasoning Frameworks:** Researched LLM-driven agent frameworks (e.g., CodePDE for generating PDE solvers) and insight into guiding unsupervised generation with model-inferencing techniques ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)).",1,Large Language Model Development And Tuning & Machine Learning For Ads Optimization And Recommender Systems & Model Evaluation And Benchmarking (Especially Llm Performance),LLM Training & Architecture,"*“TFG-Flow: Training-free Guidance in Multimodal Generative Flow”* (ICML Workshop, 2025) – Training-free guidance for generative models (multimodal generation) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)) (10 citations) | *“Functional Interpolation for Relative Positions Improves Long Context Transformers”* (ICLR, 2023) – Improved Transformer for longer context (LLM architecture) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)) (language modeling) | *“Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding”* (NeurIPS, 2021) – Fast transformer attention techniques (LLM scaling) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Stable%2C%20Fast%20and%20Accurate%3A%20Kernelized,Attention%20with%20Relative%20Positional%20Encoding)) (35 citations)","Li’s work has improved the efficiency and applicability of LLMs in industry, both by optimizing model architectures and by integrating LLMs into real-world systems (ads and recsys). His focus on evaluation and benchmarks helps ensure robustness of models in practice, and his contributions to reasoning frameworks and code agents advance LLM capabilities. Li’s collaborations on NVIDIA’s NeMo and related projects have driven both theoretical and practical advances in model deployment and agent-driven generation ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=TFG,Generative%20Flow)) ([paperswithcode.com](https://paperswithcode.com/search?order=asc&order_by=stars&q=author%3AShanda+Li#:~:text=Functional%20Interpolation%20for%20Relative%20Positions,Improves%20Long%20Context%20Transformers)).",https://www.linkedin.com/in/shangda-harry-li-7a822410a,
Shun Zhang,Embodied AI + Reasoning @ NVIDIA,NVIDIA,"Shun Zhang’s work bridges reinforcement learning and large language models ([shunzh.github.io](https://shunzh.github.io/#:~:text=Hi%21%20This%20is%20Shun%20Zhang,from%20the%20University%20of%20Michigan)). He focuses on using generative models (like diffusion models and LLMs) for planning and reasoning, including applications in code generation and human-aligned RL.","Reinforcement Learning (policy optimization, safe/adaptive RL) | Large Language Models (LLM-based planning and code generation) | Generative Models for Sequential Decision-Making (diffusion planning, transformer reasoning) | Reward Modeling and Value Alignment (RL from human feedback, ensemble reward models)","**Efficient RLHF Reward Ensemble:** Developed ensemble-based reward models to improve the efficiency and alignment of reinforcement learning from human feedback ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment)). | **Adaptive Replanning with Diffusion Models:** Introduced a method that uses diffusion-model-based planning to adaptively replan online, allowing agents to incorporate new observations during execution ([shunzh.github.io](https://shunzh.github.io/#:~:text=Conference%20on%20Neural%20Information%20Processing,planning)). | **LLM-Guided Code Generation Planning:** Combined Monte Carlo Tree Search with transformer beam search (LLM) to plan code generation tasks, significantly improving sample efficiency in automated programming agents ([shunzh.github.io](https://shunzh.github.io/#:~:text=%5Bcode%5D%20Our%20algorithm%20combines%20Monte,planning)). | **Post-Training LMs for Code and RLHF:** Researched post-training of large language models with a focus on code generation and RL from human feedback, enhancing coding assistance and human-aligned behaviors ([shunzh.github.io](https://shunzh.github.io/cv/#:~:text=,and%20AI%20for%20scientific%20discovery)).",1,Large Language Model Development And Tuning & Machine Learning For Ads Optimization And Recommender Systems & Model Evaluation And Benchmarking (Especially Llm Performance),Reinforcement Learning & Agents,"*Adaptive Online Replanning with Diffusion Models* (NeurIPS, 2023; ~3 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Siyuan%20Zhou%2C%20Yilun%20Du%2C%20Shun,NeurIPS%29%2C%202023)) | *Planning with Large Language Models for Code Generation* (ICLR, 2023; ~10 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Planning%20with%20Large%20Language%20Models,for%20Code%20Generation)) | *Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble* (arXiv, 2024; ~0 citations) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Improving%20Reinforcement%20Learning%20from%20Human,with%20Efficient%20Reward%20Model%20Ensemble))","Shun Zhang’s research has advanced the integration of LLMs into agent decision-making. His reward model ensemble work makes RLHF training more computationally efficient and aligned with human values ([shunzh.github.io](https://shunzh.github.io/#:~:text=arXiv%2C%202024%20,value%20alignment)). By using LLMs to guide search, his code-generation planner boosts the capabilities of coding agents ([shunzh.github.io](https://shunzh.github.io/#:~:text=%5Bcode%5D%20Our%20algorithm%20combines%20Monte,planning)). Furthermore, his diffusion-based replanning demonstrates how generative models can enhance sequential reasoning and adaptability in reinforcement learning ([shunzh.github.io](https://shunzh.github.io/#:~:text=Conference%20on%20Neural%20Information%20Processing,planning)). **Sources:** Shun Zhang’s publications and project descriptions ([shunzh.github.io](https://shunzh.github.io/#:~:text=Hi%21%20This%20is%20Shun%20Zhang,from%20the%20University%20of%20Michigan)) ([shunzh.github.io](https://shunzh.github.io/cv/#:~:text=,and%20AI%20for%20scientific%20discovery)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Improving%20Reinforcement%20Learning%20from%20Human,with%20Efficient%20Reward%20Model%20Ensemble)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Siyuan%20Zhou%2C%20Yilun%20Du%2C%20Shun,planning)) ([shunzh.github.io](https://shunzh.github.io/#:~:text=Planning%20with%20Large%20Language%20Models,for%20Code%20Generation)), NVIDIA profiles, and related conference papers.",https://www.linkedin.com/in/shun-zhang-1b154437,
